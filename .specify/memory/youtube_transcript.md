# YouTube Video Transkript

*Extrahiert am: 15.10.2025 08:18:04*

---

**[00:00]** So, in this video, I'll take you from zero experience in NAN and AI to being able to build and sell AI automations, AI agents, and even entire AI products. This is without a doubt one of the easiest and highest leveraged skills you can learn today to level up your career, build a business, or transform your existing business. I am Ben. I am not a coder and I started in AI two years ago. Since then, I've scaled my own AI business to over $1 million in annual revenue by selling custom and packaged NADN automation systems. And by the end of this video, you'll not only have mastered NAD and AI, but you'll know how to use these tools for actual business purposes. Whether that's selling AI automation solutions, automating your existing business, or selling productized NADN systems that can be resold to multiple clients, this course will cover it all. Now, before starting, this is going to be a very long one. I know many will not stick through, but my purpose with this video is to really make it the most practical NAD and AI course that you will ever watch. I'll cover everything from beginning to end that you actually need in order to use NAND and AI for business purposes. And I'll skip all the non-essential things that you don't really need on a day-to-day. I've added timestamps below, too, so you can easily jump between sections if you want to revisit something or maybe if you want to skip ahead if you're a bit further in your NAN journey. Now, even before diving into NAN, I want to quickly cover four things. Why to actually learn this? how to get ahead of 99% of people who are learning this, how to actually monetize these skills and help you make sense of some of the AI automation infrastructures that are being thrown around AI agents, MCP, AI systems, etc. Then we'll cover everything you need to know in NAM from trigger nodes, action nodes, data nodes, AI nodes, scraping, debugging, error handling. You're going to learn everything you need to actually be able to build production ready AI systems and automations. We're going to make it extremely practical by using lots of examples and actually applying things while learning. Then you're going to learn how to plan and scope AI automation solutions, which is something that's often overlooked but very important when learning how to build. And lastly, all the way at the end of this video, we're going to get into the most interesting part for me at least, I think, which is building AI products. This is exactly what we've done in order for us to scale to over $1 million in annual revenue, which is basically selling pre-built packaged AI and NAD systems that we've now resold to over 100 businesses. And I'm going to cover exactly how to design these AI products. We're going to build one entirely from scratch and I'm going to give you a framework on how to come up with these ideas for AI products fast. Again, this is going to be a long one, so you might need to come back to this a few times, but trust me, learning this skill has changed my life and it can definitely change yours. So, I hope you stick uh with me. So, first of all, why learn AI? AI is the biggest technological revolution in history. Most people know it, but most people stay on the sidelines. Most non-technical professionals assume this is too technical for them and they'll never learn this. And many coders or technical people often lack domain expertise. But the single biggest lesson I've learned being in AI now for two years is that this combined skill set of domain expertise and AI automation skills is what actually builds really valuable AI solutions. It's what actually gives you the real opportunities and it's what will separate you from 99% of the world. I can tell you that from my experience, this combined skill set is the number one reason for my professional growth over the last two years. So if you're an existing professional or domain expert in whatever area it is, learning AI automation is sing the single most valuable thing I think you can do for yourself right now. Whether you want to stay as a professional, you want to uh transform your current business or want to start your own business. And if you're a technical person or a developer, partnering up or getting some domain expertise combined with this AI automation skill uh will really give you a superpower in the AI era. Now, if you're just starting out, especially if you're non-technical, you will go through some pain learning this skill. Almost everyone will go through this pain excitement graph, but understanding this will hopefully make it a bit easier for you to stick through to the end where you will realize this was all worth it. Uh, as you're going to learn NAD and some technical skills, uh, this will feel like a mountain to climb, right? Which is why the majority of nontechnical people never actually tried to learn this. So, there's quite some pain to go through at the start, which I'm going to try to help you get through with this video. Once you're there and you got the essentials, you will be able to build your first automations and your mind will be blown. For many people, it is, right? And you'll be really, really excited and you'll probably have many, many ideas and things you can build, right? Which is usually here. But what you'll realize is that when when you actually want to build production ready automations for maybe clients or inside of your own business, uh you'll be all the way back down the curve again because you'll be hit with failing systems, constant errors, edge cases, and you won't even know where to start to actually solve them. And this again is where many many people in my experience give up thinking this is too technical for them. But the ones who stick through will realize that most of these errors and that most of these issues they're facing are just part of the learning process, right? that most of these bugs are very similar in nature and that debugging is part of the process and it becomes easier over time and once you're able to build production ready uh systems, right, you get the aha moment, right? Many people talk about this and it's usually the moment where your mind really opens up to many many ideas and and opportunities you're going to have with uh this skill set. And that doesn't mean it's going to be pure joy forever because with every new solution or automation or system you build, you will always run into issues. The difference is now you know that you can get through them and you know how to solve them. And in this pain excitement graph 99% of people again give up in those initial stages right and they make maybe a conclusion that AI is just a hype or that they need to hire a developer. But in my experience the people who stick through are people who make AI automation a priority in their day. You might be busy right? You might have a current job an existing business. Uh but the number one thing I see is people sticking through is making this a priority in their day-to-day. And a great way to do this uh is just by separating one or two hours in your day in your calendar to learn uh these skills because again this is going to be the highest value skill you can learn in 2025. So very quickly how do you monetize NAN and AI skills? Now there are three main ways to monetize these skills and they're all huge opportunities. The first one is through an AI automation agency which is probably the most well-known model. If you want an easy way to compare compare this to a traditional business model, you can think of a development agency or an IT agency because you're selling custom AI automation solutions to businesses. You help them automate or enhance existing processes in their business, giving them efficiency wins. You cut cost, you save time, and you can potentially really transform their business. Now this is the best model if you might not have that much professional or domain expertise because in this model companies will come to you with their existing processes and your job is to basically understand those processes and automate or enhance them and therefore you don't necessarily need to have much professional or domain expertise. I've been running this model for the last two years and we've since then also added in some consulting and some training for these companies. Another example is Liam Odley. He's a famous AI YouTuber. He runs this model with Morning Side AI. Again, this is a great model and a great business, but what you do want to keep in mind is that in the long run, this is very much a service agency. So, the only way you're going to scale this is by hiring more and more people. The second model is what I call AI services. And you can compare this to a traditional service agency like a marketing agency, an SEO agency, a lead generation agency. And in the AI services model, you sell results, right? You sell new leads, for example, new traffic, new talent, like a recruiting agency. And the big difference here is you're not selling AI, you're selling results or outcomes. You're just using AI to automate some of your service delivery processes and to enhance the outcomes. Now, this can become a really interesting business model if you have some domain expertise or if you're an existing agency owner, of course, in marketing, sales, or recruiting because you can use your existing domain expertise with AI automation skills to really transform the traditional service agency business. Because you're using AI and automation, you need a lot less people to scale your agency. You can have much higher margins and scale to very high revenue numbers with smaller teams. An example of this is called IQ, which is a lead generation agency which scaled to $6 million in ARR with only 30 to 35 employees. I also run this business model where we deliver SEO services to SAS and e-commerce businesses while heavily using AI to automate our service delivery. And the last model is an AI software which you can traditionally maybe compare best to a SAS and in this case you're building a self-s serve product right you sell a tool to a customer that can deliver an outcome now this can be a great model again for domain experts who really understand specific pain points of a specific industry and maybe for people who have some startup and SAS experience because building softwares can be difficult. Now there are two main ways to sell these AI softwares. First, you can do it more like a traditional SAS model where you sell access to your platform through maybe a subscription. There are many other ways to price uh SAS uh products. Of course, an example of this is Hoppy Copy, which is a newsletter creation tool with AI that businesses can use themselves to create highquality newsletters. But there's also a new business model now where we can actually sell the entire software to the business at a one-off price, meaning they will own the IP. And this is the model we use. We've developed a packaged NAN solution with a simple front end on Air Table, which is another tool, and we sell the entire solution to our customers at a high one-off price. And we've been able to scale this to over $1 million in annual revenue. And by the end of this video, you'll know and understand exactly how to design these packaged NAND systems that you can potentially sell for anywhere between $5 to $20,000 per solution. I'm going to build one of these productized or packaged Naden systems from scratch and I'll tell you exactly how to design these softwares. Now, these are all three huge opportunities. You can easily transition between these models too, which is exactly the path I followed. I started with an AI automation agency. I later added AI services while was building my domain expertise in SEO and then developed an AI software. So, uh think what makes most sense to you if you want to monetize and uh where you might want to start. You don't have to rush things too because you can easily transition while you're uh starting with one model. We are all early in these business models. So there's huge opportunities and blue oceans in in all of these markets. So now that you know how to potentially monetize these skills, we're moving into some of the foundational concepts of AI and automation. Before even diving into NAD, it's really important to understand the different frameworks that exist in automation like AI agents, AI workflows, and AI systems and how they're different from each other. This will really help you get a grasp of some of these foundational concepts that are really crucial before even starting to build. So, first we have traditional automation which doesn't even have AI. This has been literally around for decades and funnily enough is what can already help many many businesses make their processes uh more efficient. And this automation, pure automation is done through logic. You can think of this simply as if X happens uh do Y and then Z uh until you get your output. For example, a common automation is a lead fills out a lead form on your website, let's say on Web Flow. You then want to automatically populate your CRM with the data. So, we send it to Hopspot. And then we want to automatically send an email to that new lead. And then the last step could be to update the CR CRM again uh with a status of email sent. So, the most common use cases for this are passing information or data between different softwares and you're using this most of the time for repetitive tasks that are non-intelligent. Other examples can be for example for lead routing, invoice generation, uh report distribution and there are hundreds of of use cases more for this. Now the next framework is AI automation which is the logical next step. Now that we have AI, traditional automation is really transformed because besides just passing over information or data to the next tool, we can actually take actions on data before outputting it into the next tool. Now in AI automation, it still follows logic, right? If this happens, do this. If that happens, do that. Right? So, if we take the same example, instead of just passing the lead data from the form onto our CRM, we actually can do some extra re research on this lead. We can use an AI for example like perplexity to find more data points on this lead. Let's say their company size, the decision maker before we pass in the data into the CRM. We can now then also let an&m like OpenAI or Chacht actually write a personalized email before sending it uh through Gmail. So the common use cases for AI automation which are based on logic are for intelligent repetitive tasks. This is what we really mostly use to build production ready AI systems on NADM. Right? AI agents are getting a lot of hype and I'm getting into it in a second but this is what we mostly use and what we have to get really good at to build production ready systems. Then we have AI agents which again get the most hype in AI but it's very important to understand that AI agents are fundamentally different from AI automations. While AI automations follow logic if this then that AI agents are nondeterministic meaning an L&M or an AI agent a large large language model right will decide what to do. Now the core features of an AI agent are first of all we have this large language model in the center or our AI agent right which decides what to do with a specific input or task. This L&M or AI agent usually has access to memory so it can remember the conversation with the user. Uh second, it can have access to knowledge or rag where we can give an AI agent more context for example on our business. Uh so it can maybe respond to specific questions on our business. And third, an AI agent can have tools which can be software or entire AI automation workflows in order to take actions. Now, because an AI agent can make decisions on what to do uh with a specific task or input, an AI agent can be great for open-ended tasks where the path it has to follow isn't always clear or always the same, just like I showed you before in the AI automation. And because of that, the best use cases for AI agents at the moment are generally more customerf facing use cases. Uh think think of customer support chat bots like lead qualification bots and voice agents where it has to talk to a human. Now why is that? Because every customer interaction is inherently different. A different course of action could uh be possible for each of the cases. For example, uh here we have an AI agent who has access to a tool to update hotspot to send an email to schedule a calendar meeting and to do research with perplexity. Now, let's say this AI agent is on a website uh and that can help a potential website visitor answer questions about the business uh through maybe the knowledge base, but it can also schedule in a meeting with the team if it's a qualified lead. It can send an email uh with the confirmation of the meeting and it can update the Hopspot uh CRM with the new uh leads data. Right? But it's very important to understand that because AI agents are non-deterministic, meaning the decision-making process is not defined by logic, these systems can be much more errorprone and a lot less reliable. Therefore, if there is a specific process in place, it is far more efficient to use AI automation than AI agents. Before generally automating a task or a process, the task generally has to be clear for a business, right? Or for yourself. And once it is AI automation is generally a more efficient and reliable way to automate a process right and therefore the main use cases for AI agents are really more of these customerf facing use cases where we need that flexibility where we need the decision- making the memory and the knowledge now the second use case for AI agents is the assistant use case meaning they assist us while we are there as a human so we have lots of human in the loop and like that we can sort of error correct our AI agents now you can see tools like JPT and claw transforming more and more into AI agents with things like MCP which I'll get to in a second where they can actually start taking actions for us in software and we can also give them custom knowledge bases etc. But I want to be clear here uh for example in my AI automation agency and in my AI software business we rarely use AI agents like this because of the nondeterministic aspect we are not very much focused on these customerf facing use cases like chat bots etc. So although they're exciting and they sound very cool, AI agents, if you're not specifically focusing on those use cases, you'll mostly be working with AI automations. Now, the way we do use agents is inside of AI automations, right? And the big difference here is that the AI agent is not the brain of the operation. It doesn't make the decisions on what to do with a specific input. It's just one has one specific task in the AI automation workflow. So this can be sometimes a use case because AI agents can be great for sort of research purposes because we can give an AI agent multiple tools like uh Perplexity, Hopspot. We can let an AI agent do deep research on a specific topic but inside of a logic chain. And don't worry if you don't understand all of this just yet. Uh it will make a lot more sense when we uh dive into the building. Now lastly, you might have heard uh of MCP or model context protocol already. Now to make it really easy and practical, what an MCP basically does is instead of us having to connect each of the separate tools from a software like for example creating a calendar event which is a separate tool getting a calendar event updating a calendar event all separately which can be very timeconuming to set up. We can give an AI agent access to the Google Calendar MCP. And the Google Calendar MCP will already be able to execute all of the tasks possible in Google Calendar, even more than these, right? Making it a much more efficient and fast way to set up a complex agent system. Now, I'll dive a little bit deeper into MCP later in this video. So, don't worry if you don't completely understand this, but this is a very simplified way to understand uh MCP. Now lastly we have AI systems also called productized services AI software or AI SAS there are many other names but what this really means is that it becomes a tool it becomes a self-s served platform for a customer instead of just a custom automation running in the back end now this might sound complicated and you won't have to understand all of this in detail yet we'll get to that later but uh in reality in 99% of the cases these softwares or AI products or AI SAS are just multiple AI automations strung come together with a front end or user interface and a database to store the information. Each automation puts uh the output back into the user interface, lets the user take action on the output, and then run the next task in the workflow. And by the end of this video, you'll learn exactly how to build an AI software or an AI system like this. But I just want to show you and help you understand how simple many of these products or softwares actually are in the back end. This is also the exact infrastructure we use for our AI SEO software that we sell to clients. Can show you a quick example here. We have our AI SEO agency in a box which we sell to clients and this is basically what the client uses to interact with the system. It can create blog post, generate ideas, uh post to blog post, generate images, etc. So this is just the front end and then in the back end we have naden. And this might look very complicated but as you can see these are just smaller automations strung together and we've built this out over time to become more and more complex but we probably started out with like 20% of this entire workflow. And again you're going to understand and be able to build something like this by the end of this video yourself. And we're going to build an AI product from scratch in this video too. Again don't worry if this doesn't make sense yet or is this too complex. I just want to give you the highle overview of this is not rocket science and you will be able to understand and potentially build out a product like this by the end of this video. Okay, so by now hopefully you have a better understanding of the different automation frameworks out there. Now we're actually going to get practical and dive into naden. We'll be covering literally everything you need to know from beginning to end to be able to build any automation solution. We'll start with getting you familiar with uh the platform, the basic concepts and some examples. Then we'll cover all the essential notes and skills step by step. And we keep it all practical by actually applying these concepts in real world scenarios. So first we're just going to go over the basics here in Naden. We're going to set up a quick account and go over the key concepts that you have to understand. Now we're not going to spend too much time here because I want to keep this practical. Then we're going to cover every node you need to know in Naden to start building basically anything. And finally, we're going to build some things from scratch. And by the end of this video, you're going to learn how to build entire AI products from scratch. Now, if you don't have an account yet, you can go to naden.io or use the link in the description below if you want to use my affiliate link. Now, a huge benefit of using nadn over other popular automation platforms like make.com, zapure, etc. is that in general, it is the cheapest to run of all of these automation softwares. Second, we also have the most flexibility. Although it is very simple to use for non-coders or non-technical people, we still have lots of potential for the long term to build more and more complex systems, right? Because we can even use code in naden. But maybe more importantly, NAD is the only one that uh supports self-hosting options. And this basically means you can run NAD on a local server. And this means you can keep your data private. And second, you can save a lot of cost if you're really going to run automations at scale. Right now, we're not going to cover that uh setting up self-hosting in this video because it's definitely not necessary and probably not recommendable to do when you're just starting out. I highly recommend getting some experience first and really when you start running automations at scale, you can always switch to the self-hosting option. There are many tutorials on the internet on how to set it up and it's quite easy and fast to do. Now, lastly, before creating an account, it's worth noting that uh uh Naden has hundreds of community templates available as you can see here. These are basically automations pre-built for you that you can just copy and paste. I also have dozens of AI automation and AI product templates available in my free community and my community, which you can all find in the uh link in the description below, too. It's definitely worth checking out some of these templates. Now templates are great but you should think of templates in general more as giving you sort of a head start on a specific automation or using them for learning because most business processes and processes in general are so unique to each company each industry and each person that they have to be heavily adapted or even sometimes built from scratch in general. So unless they're productized NADN uh automations which we're going to learn at the end of this video uh and you can make them resellable and reusable for multiple companies uh in general you have to heavily adapt them. Um but still it can be worth checking in. Anyway uh here we can just sign up for a free account. We get uh for the cloud version we get two weeks of free trial. So you can set up your your own account here. You have a little bit of an onboarding flow but it's quite straightforward. Now once you're set up you'll land in your dashboard. Not too much to cover here. speaks for itself I think. Uh but some important things here is the workflows here are all the automations you've built uh are stored in here. Then we have credentials here where all the connections with softwares you made are stored so we don't have to redo them each time we use a specific software. Then we have the executions where we can basically check all the automations that have run in our account both the successful ones and the errors. And uh for the rest here in the top we can create a new workflow. On the left panel we don't really have to do a lot. We can set up a project basically like a folder here. Here we can also access the templates uh but not too much you're going to use on a day-to-day here. So we're just going to go to the overview. So what I've done for this video, I've created an entire NAD course template here and this basically covers everything we're going to cover today. All the nodes, all the important concepts you need to know in Naden to basically be able to build any automation solution. So we're going to cover everything here. So, this is just a good resource for you if you want to dive a little bit deeper in specific con uh concepts uh want to reread. We're going to cover this all in this video, but it can be a good good resource for you if you want to dive a little bit deeper or if I went too fast over a specific topic. So, you can just import this entire template into your own nan account, right? The way you do that is just by going to the overview. You create a new workflow and from there you can import uh from file. Now, that entire naden course template will be available here in the free resources. So I haven't posted it yet uh but it will be here uh when I launch this video. Uh so you can see I have many other templates here. All you do is you go to the JSON, you download it, you go back to the the workflow here, the canvas, you go import from file, you go to you select the JSON, and you'll see that it automatically is imported. So that's it. So we're going to use this N course as a guide basically uh in this video, but we're going to be really practical. We're actually going to build out some some automations. So before diving into the course, I want to give you a quick example and get you familiar with some of the key concepts here in NAND. So here I have a quick example that I set up which is a LinkedIn uh outreach message generator. So basically generates a personalized LinkedIn outreach messages for potential leads. Now this is a similar system that I built out for a client a while back ago which was a LinkedIn outreach agency which basically manages LinkedIn outreach for their clients and they heavily personalize the outreach to get higher response rates uh rates. So this automation can help uh basically get higher response rates for potential leads through LinkedIn outreach. Now here we have the canvas and here we can build out our automations right and here we also can name our automations. In this case LinkedIn outreach example we can add tags. So these tags we can then later use inside of the dashboard to filter our automations on. In this case I can call it Benai community. And we have the editor here where we're building out our automations. We have the executions where we can check the past executions. And we have evaluations which we're not going to cover now uh but later in this video which is a bit more advanced. Here we can uh put our automation workflow on active uh to run it into production uh but we can still test it when it's inactive. We can share it here too. We can also download our template here which we can then share with people uh so they can import it into their own naden account and of course we can also import from here. So that's really all you need to know here in the canvas. Then there's some key concepts you have to understand. So naden works with nodes. Nodes are basically all these steps here. Data flows from left to right in a net. Right? So here we have our trigger and here we have the output and data flows from node to node. So we have many different types of nodes. We have trigger nodes, right? Every automation should start with a trigger node. There are many different types of trigger nodes again which we're going to cover in the course. Then we are uh we have software nodes for example here air table and we have AI nodes right AI agent node here and here we have a basic NM chain which is also an AI node. So I'll show you a quick example of this in action. So here I have a lead database inside of air table. I like and we like to use air tableable a lot as our main database. You'll need a database anyway. Uh when you're working with these automation solutions because you always have to store data generally somewhere. Uh so many people use Excel Google Sheets you can use that too but I like air table because you can build front ends on top which I'm going to show you later. So in this case I just have three uh leads here just random leads including myself. air table notion and here you can see we have three columns with the LinkedIn messages. Now here the personalized LinkedIn messages should be put out, right? So that's what our automation is going to do. We also have some lead data here and basically this automation. We can now click here on execute workflow where we can basically test our automation and you'll see that it started now. So basically this node here got the data and the leads or the rows from air table. It passes that into the AI agent which does deep research on these leads which we can then use in order to personalize our outreach messages which is what this AI node will do. And then the personalized LinkedIn outreach messages will be updated inside of the air table. It's going to take a bit so I'll speed it up. So our automation has now finished which you can recognize because all nodes are green which means they all ran successfully. So if we go back to the lead database we can now go to the messages and here we find now we have personalized LinkedIn outreach messages. Now this uh system is programmed to message from u my company. So uh this is probably not the best example because I'm sending a message to myself. But just to see the output. Hey Ben, I saw your workshop with Capria on AI automation. That's actually really good because basically in the deep research it found that I did a workshop with a VC called Capria. So it really looks like I did my research, right? Love how practical and communitydriven your work with Ben AI seems. Would be great to connect and swap notes. Right. So generally for first outreach messages on LinkedIn, you don't want to pitch your services. Yeah, you just want to go for the connection first and later uh pitch it. So here we go. Hi Henry, I've been following Air Table shift towards enterprisegrade apps and AI super interesting evolution from its spreadsheet roots. Thought it'd be great to connect. So these are pretty good. Hey Tim, I've been following Notion's push into AI super interesting direction. Thought it'd be great to connect with someone behind the scenes there. So anyway, you get the idea. Uh and again this entire template will also be available uh for you to download so you can adapt this or use it yourself. Now this is actually part of an entire end-to-end LinkedIn outreach product that we built on NAN which uh finds new leads, does personalized outreach, um actually sends the messages and can even manage your inbox. I'm going to show you an example of that one later in this video. For now, don't worry if you don't understand all of this yet. All I want you to understand is nodes. Data flows from left to right. We always start with a trigger. And lastly, what you have to understand is how nodes work. So I can dive into this AI agent node very quickly. So all you have to understand here, this might look complicated, is on the left side here, we always have the input data. So basically it means we have access to the data of all the previous nodes here which you can see and this data we can use here in the middle part which is the configuration of this specific node and here we basically decide what this node should do and we can pass in data from previous nodes into this node. So the way we do that is by just dragging and dropping. So you can see I gave the AI agent here access to the lead name, the company name and the company website. And the way I did that is by just dragging this in. And this is what we call variables or expressions in NAND which are constantly going to use. And then here on the right side we have the output of this specific node. So in this case the AI agent outputs a research report on the specific lead which then of course going to pass on to the L&M which can then write personalized messages based on that. So these are the key concepts. Now we're going to dive into the course and you're going to learn everything you need to know to be able to build automation solutions like this yourself. So if we dive into the course, we're going to start with uh trigger nodes. So triggers and web hooks are important because every automation in NAN has to start with a trigger. And they're basically two types of triggers. We have triggers that start from within NAN which are mainly these four and uh triggers that start from outside NAND generally from other softwares. So let me just open up a new workflow here. So I can click here and create a new workflow. And you always get this first plus icon here which automatically allows you to select the trigger. Now you will see here that we have many options, right? So the first one is the trigger manually which we also used in our original example. And in this one we can basically manually trigger automation. So this one you're going to use a lot when you're building and testing out your workflow because we can just decide to start it whenever we want. So this basically does nothing. As you can see, there's no output. It just starts the automation. And the second one we can use to start start it from within n is on chat message. Now this on chat message is mostly used again for sort of these chatbot use cases or assistant use cases. So generally we connect this to an AI agent to sort of get a conversational experience. You can see here if I click on open chat, I can say hi and now this is triggered and of course we also get the data here which we can then pass on to an AI agent. Now, we're going to cover this more when we talk about AI agents later in this video. Uh, but for now, not that important. On a schedule trigger, this one you're going to use quite a lot, too. And this one basically allows us to trigger this automation on a specific time interval, meaning every 3 minutes, every 12 hours, twice a day, etc. So, we can decide here, let's say hours, and we can say every 12 hours. So, every 12 hours, this will now be executed. So, that's it. And then we have the last one we can use for starting from within NADN which is when executed by another workflow. This runs the flow when called by the execute workflow node from a different workflow. So in reality you're going to use this one when you build really complex automation systems and you want to reduce the complexity a bit by separating your workflows. Then you can use this one to basically call a part of your other workflow in this new automation here. Now, in general, you're not going to use this quite a lot, especially in the beginning. I don't even use it that often. So, don't worry too much for uh with this one for now. Another use case for this one could be to sort of reuse one specific automation flow for multiple other automations. But again, don't worry about this one too much for now. And then for the triggers from outside NAN, uh we have the onapp event here. So here you can see and this is the big advantage of NADN is we have hundreds of these native integrations already set up for us. Basically allowing us to make it a lot easier to connect thirdparty softwares to NAD than if we wouldn't have these native integrations. So here you can see we have hundreds of these software integrations and there are two types of uh software triggers right we have instant triggers and we have polling triggers. Now what's the difference? Instant triggers basically allow us to get this automation to get triggered as soon as a specific event happens in another software. So for example, if we take Calendarly here, we can decide what the trigger is. In this case, I'll do on event created. And what you'll see here is I can decide on which event this automation should get triggered. So in this case, let's say event created. So as soon as a new event is created in Calendarly, this automation gets triggered. But there are also many softwares that don't have an instant trigger. So if I take for example air table, if I click here on on new air table event, you'd think that it would happen at a specific event. But what we actually see here is poll times and this means it's a polling trigger. Now what's the difference? This doesn't actually trigger instantly when something specific happens in air table. This basically checks for updates every minute, every hour, every day, whatever you prefer. And if there's some specific characteristic or something is updated in the air table, you can decide to to let it trigger. But the big difference is this doesn't happen instantly when something happens in air table. It just checks for updates every minute, hour, day, and then it gets triggered. Of course, we can define here in the configuration when it should actually run something like maybe let's say a new field is updated then run the automation. But the important thing to keep in mind here is that it's not an instant trigger. Now why is this important too? Because if you let's say you check every minute for updates on air tableable, it means it's going to execute the workflow every minute. Meaning you'll be charged for an execution every time this runs. So this might not be an ideal setup if you want air table to only be triggered on specific events, right? So what do you do in that case? You can use a web hook. And a web hook you can basically see as a URL. So here we have a web hook which is going to be really important node, right? Which you're going to use a lot in practice. Now two use cases for this web hook. The first one is when we have a native integration with a tool like air table but we don't have an instant trigger then we can use a web hook because a web hook basically allows us to get that instant trigger. So what you can see here is we get a URL a test URL and a production URL. The test URL we can use when we're testing out our workflow and when we put our automation live we'll use the production URL. Now, now this URL we're generally going to add somewhere in the other software to basically tell Air Table, hey, if a specific event happens here, please send over data to this URL and this will trigger the automation here in Naden. So, that's how we can set up an instant trigger with a software that doesn't have an instant trigger here in Naden. Now, the second use case is if we don't have a native integration here from within NADN, we can also generally just use a web hook to be able to trigger it from a software that doesn't have a native integration. So for example, my community runs on Circle. Now Circle doesn't have a native integration with NADN. So here's an example workflow uh for a Circle customer support agent that we use. And in this case, I used that web hook and added it into the settings in Circle to basically as soon as someone posts a tech problem or a tech issue for this automation to get run. Now again we're going to show an exact setup of the web hook for air table also later in this video but generally in all softwares you have some place where you can add in a web hook and let them know that they have to send data when a specific events h happens. Now this is different of course for off software so I can show you but later I'll show you from scratch for example how we do this in air table. Now one more trigger that you might use is the onform submission and this basically allows us to create a quick form from within nad which we can then use also in a URL which we can for example give to a client. So for example on this one let's say we actually want to uh trigger it from a form submission where someone fills in a new lead. We can just uh delete this one. We can add a new trigger and here you get on a form submission. So here we can basically build our own form. So we can call it let's say lead form. Right? And here we can decide which fields we want. Right? So let's say lead name. We can define which type of field it should be. Right? So in this case let's say text and uh we can add in another one let's say company name company name right and if we now click here on execute step you'll see that we get a little form here and we can also get this if we put it in production we can get a link right and as soon as we fill this out automation will be triggered right so this can be useful if you have an automation workflow that you quickly want to give to a client or you can fill out a form to start the automation This can be very useful. So you can also use this, of course, as a test URL. So you will use this one when you're testing, right? And you'll use the production URL if you actually activated your workflow. Now, another thing NAN allows us to do is to have multiple triggers in one inside of one workflow. So for example, uh in this one, we want to be actually be able to trigger it from a form, but also want to run this automation every day. And we can just add another trigger. We go to the plus icon all the way at the bottom. We see add another trigger. And let's say in this one we choose on a schedule and we also want to run it every day at a specific time. All we do is add it to that first node and now we have two triggers. You'll also see that we now have a drop down here. So we can basically when testing it decide from which trigger we want to uh test it. Uh but if we run it in production it will use both of these triggers. Now the next thing we need to know is action nodes. Action nodes and APIs in NAN. Now, of course, the big advantage in NN again is we have hundreds of these native integrations already set up for us, right? Making it a lot easier for us to connect it to third party softwares and applications. Now, let's say we're just going to build out um the initial part of that workflow you just saw in the example. So, in this case, we're going to have to retrieve all the records from Air Table, right? All the leads from Air Table we want to get here inside of Naden. So, we're going to use an Air Table action node. So, we can just go here on action in an app, right? And here you'll find all the software. So in this case we're going to use air tableable. And in air tableable you see all the actions we have available that we can take inside of air table. So we can create a record, delete a record, update a record. But in this case we need uh to search records. Now you might wonder why not use get a record because get a record only gets us one record. That's why we're using the search records because we want to retrieve them all. So once we add an action node and this this configuration will be different for every action node of course because you'll be able to take different actions and different configurations on different apps but the first thing you'll almost always see is the credentials and that will be the same for AI nodes too and the credentials basically uh is where we set up the connection with our specific software. Now you can see in my case I've already set up the connection but if you don't you can go here to create new credential and this will be different for every software but here we'll see what we need to make the connection with air tableable. Now a very useful thing that NAN has done is every single one of these action nodes has a link here that tells you exactly how to set up um this this connection here. So if I open the docs here you'll see and it will let you know and then exactly where to find this access token. So go to the air table builder hub right and here I can create a new token in this case for air table let's go three and I also explain the configurations right so in this case I have to add scopes and scopes basically tell a software what am I allowed to do in the software in this case for this one I need these three scopes so if I go here to air table I need to add in those three data read write and what's the last one schema basis read. So this one. So now we've added the scopes and now we can here decides which which of the bases which of the tables inside of my air table it has access to. Again you're going to you have to use a database when you're going to start building on an end generally. So I highly recommend you make an account on air table. Of course you can use Google sheets or or another one. I'm a big fan of Air Table because we can build user interfaces on top of it very easily, which is actually what we use to build our AI products and make NADN solutions resellable, which I'll again show later in this video. In this case, we're just going to give it access to the lead database, right? And then we create a token. We copy this one. We go back to N. We add this in. And now we have the connection set up. You can see connection tested successfully. Now the thing is now this credential or this connection is stored forever. So every time I'm going to use the air table node it will always be already connected right that's the big advantage here. Now this configuration again will be different for every single one but as it's now already connected to my base you can see that I it already lists the database here that it has access to. So I can just choose this one. And of course, we want to retrieve the leads from this table which is going to load in a second.

**[41:53]** Here you see now we have leads and now we can also filter by formula. And this basically allows us to only retrieve let's say specific type of leads only when they have more than 10 people in our company for example. Uh but we're not going to use that. We want to retrieve them all. Then here we can also decide return all or we can limit it to let's say only two leads. In this case we want to retrieve them all. They're only three and usually here you have some extra advanced options. Now again every action node will be a bit different but the credential part is always the same. Now some credentials might be a bit harder. Uh we also in our community have an entire section on how to set up integrations with the most popular softwares. Navidid, our community manager and tech specialist has uh built this and make quick videos on how to do set up the connections between all of this. You can also book in Navevid for any tech issue or tech problem you have. You have unlimited one-on-one calls with Navidid in my community. So, if you need some help while building out your first automations, uh definitely interesting for you to check out and Navidid can definitely help. So, now we can uh execute the step here and we can just test it here and you'll see it retrieves all the data from the database. So if I go here to the table view, you can see we get all of the three rows back. Now sometimes, of course, we don't have a native integration inside of NAD. So then we can check out first of all if there's a community node. This is basically just people in NAN's community setting up these connections uh themselves. So sometimes that's worth checking out. For example, uh they usually appear here too. So this one for example is a community node. Usually have to install this one first. Now in this case, I've already installed it, but uh that might be worth checking out too. But sometimes of course we need to set up the connection manually and we do that through APIs. So I'll cover very quickly what APIs are. But and again NAN makes it really easy for us to set up custom APIs too. So very quickly if you're not familiar with it yet if not you can skip this but what are APIs? APIs are application programming interfaces and it basically is what allows different softwares to share data and work together. Right? And of course we use that all the time here in NA. All these native integrations you we've just set up for example those are APIs too right so an API basically consists of an endpoint and the endpoint is like a specific address or URL where the API is accessed and each endpoint usually represents a specific action. So for example if you want to create a HubSpot contact right a CRM contact we might have a URL like this contact/v1cont and this is just how HubSpot knows what kind of action you want to take in their software. Then second we have HTTP methods. And the HTTP methods basically define what kind of actions you're taking. Now in general you only have these four. You might sometimes have a different one but usually it's just get. And get is usually used to retrieve data from a software like pulling a context details. You have post which usually is to add new data or to create new data into the software. Um then we have put or patch which is usually used for updating uh existing data. And then we have delete. So the example for this Hopspot creating a new context of course is post. Then we have headers. Headers carry metadata about the request like instructions for the API on how to process the request. Now almost always the ones you will see is first of all content type and this defines basically in what structure the software can receive the data. Now this is almost always going to be application JSON because 99% of applications or APIs uh use JSON as data structure which you're going to get to in a second. And then we have authorization and this tells the API who you are right and that's usually done through an API key. So for example in uh HubSpots we have authorization which is header one and content type header two and the value is bearer and your API key and the value of content type is application JSON. Now again all of this information is always available on the documentation pages of these softwares. Right? So you don't have to make this up yourself. You can literally just copy and paste which I'm going to show you in a second and and it then makes it even easier. So we don't even have to copy and paste everything like this. So then lastly, we have the request body. And the request body contains the actual data you're sending. So if we're updating a contact in Hopspot, we're sending the actual contact details that we want to add to HubSpot. So here's a quick example. So we have to do this and set this up uh through an HTTP request node, which I can show you quickly here. If we want to set up a custom API, we have to use HTTP request. And you'll see that we get all of those fields that I just explained in here. So let me just show you this quick example here with HubSpot. So in this case the method is post the URL we filled out the URL the authentication is none. We have two headers uh right the authorization with the API key and here you would have to put your actual API key of course and the second header is content type application JSON and then here in the body we have the JSON that actually sends the contact details of the lead to update into HubSpot. So let's say in our automation, we're going to want to add a new node here. Uh because let's say we want to use Perplexity to do some more research on these leads. Now Perplexity, let's say, doesn't have a native integration here in NAD. So how are we going to set this up? So first, we're going to use an HTTP request node and this allows us to set up a custom API. Now again, N makes it a lot easier. We don't have to copy and paste everything. I'm going to show you that in a second. We do that with this button here. So if you have a software you can just go to the documentation page of that software. So in this case we're going to use perplexity documentation generally you can just find it like that right or API documentation right here we go. Now with most softwares you end up on a documentation page right away. I think with Perplexity here it is right and here you usually get all of the actions you can take in the software. So these are all basically all the options or API calls you can make. Now in this case we're going to use the chat completions which basically allows us to do some extra research on these leads, right? Which we can then later pass into the NM when we're generating personalized LinkedIn messages. So what you want to be looking for on the documentation page when you're setting up custom APIs is curl, right? Because why is that? Because we can literally just copy this, go back to n use it button here with import curl. We paste it in and you'll see that everything's already filled out for us. So we don't have to start manually copy and pasting all of the data and the parameters and the headers etc. It will already be filled out. Now the only thing you generally have to do yourself is the authentication right or the credentials. So in this case you can see here that the authorization has bearer and then we have to uh exchange this tokens for the actual API key. So in this case it's uh here on the API keys here can create a new key. I can copy it and paste it in here. And now the connection should be set up. And again here now in the JSON these of course are the parameters. So in this case we want to define what these parameters are. And in this case with with uh perplexity we can we have to define what the prompt to perplexity is. What does it have to do deep research on? Now in this case, of course, we want to do deep research on the lead. So we can say here something in content like research this lead and this company. Of course, we want to now pass in variables. Now this is the first time we're going to take variables again. So here in the input, we have access to all the all the data from the previous nodes. So we can go here into the air table node and we can look for the specific uh name of this lead which case it's me. We can just pass in the variable here. I went wrong has to go inside here right and last name. Right. And we also want to add in the company name. Right. And maybe the company URL just to give it a bit more context. Right. And that's it. Now we've set it up and now we can test it by executing the step. Again, JSON we're going to cover in a second. So if you're a little bit confused there, don't worry. More important that you understand these APIs and how to set up these custom APIs yourself for now. So you can see it worked. So you can see now we get uh some research data back here all the way at the end. Ben Fernando is the founder of Ben AI company focused on helping businesses become AI first. So now that we know action nodes and trigger nodes and setting up custom APIs, we're really halfway there. All we're missing really is AI nodes and data transformation and data flow nodes. Now in order to understand data transformation and data flow nodes, which are really important in NAD and we're constantly going to use, we do have to understand JSON and data types in NAN. Now, this might sound complicated or boring if you're just starting out or don't have a coding background. But trust me, it is not rocket science and it is really really important to understand data structures and JSON in order for you to work efficiently with NAN because essentially what we're doing is we're just constantly modifying adding uh data or or deleting data in these automation workflows. We're constantly working with data. Even these entire workflow automations are just a JSON. So understanding it is key also for error handling and debugging because almost all the errors you're going to run into are going to have to do with data types and data structures. So let's cover it very quickly. So we're going to show this by adding in an edit field node which you can find here in the data transformation and you're going to constantly use this field or this this node sorry because this node allows us to modify add or remove items or fields. So we're going to add this one here and you've probably already seen this but we have basically have three ways to visualize data here in Naden both in the input and the output. So we have the JSON which is the original data structure right and then we have the table which is just a different representation of the JSON right and a schema which is also just another representation of the JSON. Now generally I like to use the schema because it makes it really easy for us to drag and drop right to see the data that we got back from the previous node. We can also do that from the table node right we can also drag from this right and also from JSON right now all JSON is is basically a structured way to store data and 99% of softwares or APIs use J J J J J J J J J J J J J J J J J J J J JSON to send or receive data, right? That's why it's so important. Now JSON you can usually recognize by these curly brackets here. And all JSON has is keys and values. So the key in this case is ID, the model, the prompt tokens. These are just uh the parts on the left and then we have the values which in general here in NN are the variables right in this case the ID number the model sonar uh etc. Now in order to understand JSON fully we have to understand data types which is going to be very important in the net. Now there are five main data types we have to understand. The first one is a string. A string is basically you can see as a text value. So in this example we can recognize a string by the double quotes here in the value. So in this case the ID is not ID number is a string because we see the double quotes here the the sonar here is also a string right now we can also in this field set a new string for example uh we can change let's say uh the name of a specific key so let's say we call it llm model we can just drag in this one right and now we will set a string right we can also identify a string in the schema by seeing in this little AB here, right? Now, then we have a number. Then the second one we have to understand is a number. And a number speaks for itself. But here you can see all the green ones in NN here are numbers. And a number we can identify by first of all being numerical. And second of all, it doesn't have the double quotes because we can actually store a number value in a string too. But in this case, you see that the created or the prompt tokens don't have double quotes. So it means it's a numerical value, right? It's a it's a number. And why would we store that as a number? Because then later we can execute functions on these numbers. For example, we can filter on the company size. Things like this, right? So for example, we can set a number here quickly. Uh let's say company size, right? And we we can go back here to search records and find the company size. There we go. You see that's already a number. And if you execute this step, you can see and you can also in the schema recognize it with a hashtag or a pound symbol. So the next one you need to know is boolean which is just a fancy name for true or false right that's the only two values this uh data type can uh store right so uh the way we can for example we'd have qualified lead or not right so we say that this lead is qualified right and this will be stored in a boolean right and you can uh recognize it here by the checkbox in the schema and inside of the JSON we can recognize it because it's true or false and without the double quotes right because of course So we can have true as a string value too but then it would be in double quotes. Now boolean is important because sometimes softwares for example uh just have a true or false or a boolean value. Let's say in our air table we have the option of having a boolean value inside of our database. So air table is going to expect this data structure when it receives it for that specific field for example. Then we have uh array which is just a fancy word for a list. And for example, if we go back to the HTTP request and the way we recognize an array inside of a JSON is by the uh square brackets here. So you can see that the citations is a list. And you can see that inside of the list we have all the different resources that perplexity used to get the research report from. Right? So we have all the links here and they're stored in an array and each of the different items in the list is separated by a comma. So I can create a new value here with resources let's say and I can just drag this array in I can execute the step and you'll see that now we have resources here with an array. Now the last one we have to understand is an object and an object is just multiple key value pairs grouped together. So if we look at this one again, we can see that we objects we can identify here in the schema with a little box, right? And you can see that the little box here has multiple key value pairs, right? So it has prompt tokens, completion tokens, total tokens, cost. So we even have an object inside of an object which is called a nested object. Not that important for now because as long as you understand these five, you understand every data structure here. So if you look at this in a JSON, you can see that this here is an object inside of usage because it has multiple key value pairs, right? And this one cost for example is another nested object. So that's really all you need to know. So if you want to create new values, right, in uh in NAN, you can just make them yourself here too, right? So if let's say I want to create an array, right, and I want to call this, let's say, email list, right? Now that you know the data structures, we can make them ourselves. So the way we make a list for example is by square brackets. We have to open it, right? Then we have to define which type of um data type we want to add in. So let's say now we want to do emails. So there those will be strings. So we have to open it with the double quotes. We go then at benai.co. We close it with the double quotes and then a comma if we want another in the list. So Aaron at benai.co co and again we have to open that with the quotation marks right and then we can close this with a square bracket and then we've built an array right because if we execute this now you'll see that we have built an array this is exactly what I put in here right but of course we can also add in numbers here right if we want to add that to the array and in this case we don't use the double quotes so you can see now I also have added a number right and we can do this for anything right so we also build a string. We can type in anything. We can do a number or we can do a boolean. Now, that's really all you have to understand for now. This is going to make a lot more sense when we're going to work with some data transformation and data flow nodes and you'll get more and more familiar with this. But just understanding this really brings you almost all the way there. It's going to help you a lot when debugging and doing error handling because a lot of times it's going to have to do with these data types. Now, in practice, this edit field node you also use quite a lot to clean data up. So for example in this uh uh perplexity API output we get a lot of data that is very irrelevant to us right this this prompt tokens etc right so what we really want out of this one is just the research data right so what we can then do is just simply clean it up by only sending this to the next node so we can call this research data right and then we we're left with only this right so that's a common use case for this edit field node there's one more thing we have to understand about data types and data structure so there's one more data type besides JSON which we're going to have to work with in NN which is going to be binary data. Now binary data is just a fancy name for uh data that is not textbased meaning it can be a document, it can be an image, it can be a video, anything that is not text based and it will be represented a little bit different and the way we work with it is going to be a little bit different. So I'm going to show you a very quick example here um by setting up uh uh let's say a quick on form submission. We're going to create a form where someone can upload a file, right? So file upload just so you can show how it's represented here in then we're going to add a form element which is going to be file right and the element type here we can now select file and if we now execute step here and we upload any file can be a video image document etc. Let's do this thumbnail and I click submit. You'll see now in the workflow that we get an extra uh uh data representation here which is binary. So we still have the JSON. You can see in the JSON here we have an image or PNG, right? And if we want to work with this image file, we have to work with the binary data. So for example, we're going to do something with this image right now. By the way, if you want to deactivate parts of your workflow, you can just select them and click D, which sometimes can be useful if you want to build something out and test something else. uh because it won't work if you still have this on active right so let's say I want to do something with this binary data so I can maybe go with the Google Gemini that can analyze images for example so we can say analyze an image here then you'll see this specific action node right or AI node can accept uh different input types so here I can actually select an image URL or binary file so in this case I can select a binary file and in this case the input data field should match the name of this binary file which in this case is file. So as long as I just put in this then it will be able to process this binary data and execute the step. So let's just say we use 2.5 pro here to say or let's say two uh what does this image say?

**[60:55]** Right? It can now actually use this binary file and and use it in this action node. So important to understand you'll be working with that a little bit. Image says easiest to start. Perfect. So it worked. So that's it. All you need to know for data types. Now we're going to go over to the next part which is going to be data transformation and data flow nodes. Now these are really important and in practice you're going to use quite a lot. Now the first ones are with the filter if and switch. Now they speak for itself but I'll show you a quick example of each one. So let's say for example here if we execute this again you can see that we actually get three records back from air table right three of the different leads right then for each of the different lead it will do the perplexity research and then inside of the data of each of the the the perplexity results we filter out here right to only get the research data but we still as you can see get three different items and the way this works in nan is basically it runs this HTTP request because there are three items three different times straight after each other. Right? Now let's say for example we only want to process leads that have more than 10 people in our company. Those are qualified leads. So then we can use a filter. Right? And with this filter we basically can just pass in the previous data. So let's say uh we take the data here from the air table and here we can just set up conditions right. So in this case we're going to do company size. Right? it identified that it is a string sorry a number right and then we can use um conditions based on numbers in this case we can go with is greater than 10 right and if I now execute this step you'll see that we only are left with one item and it discarded two items so if we look at this now instead of three for the next one it's only going to process one the only lead that has more than 10 employees in their company so that's the first one filter Right? So it doesn't filter like this edit field note the data inside of the output of one request but rather it filters the amount of records in this case. And of course we can set up all kinds of conditions. We can also add a more complicated. We can use and which means it has to comply to both of these conditions in order to continue. For example, and also the delete has to be qualified or uh any other variable we have. Or we can use or which is any of these conditions should be matched for it to be filtered out. So the next one is the if node. So instead of filtering them out, we can reroute based on conditions. So if we use the the if node here, right, you'll see that again we're going to have this condition. So we can for example use the same condition as before. So company size is greater than 10, right? And if I run this now, instead of just filtering it out, we get two strings here. Basically, meaning we can follow another route or another automation with the low uh quality leads, let's say, and another route with the high quality leads. For example, the low quality leads, we just send them to an email list and the high quality leads, we we put them on high priority. So in practice, you use this quite a lot. Now the if node the limitation of the if node is we only get two routes. So there's a third option which is the switch node where we can use multiple routes basically unlimited routes. So let's say we want to actually route it in three directions meaning let's say we want to have one route uh generally you use rules here right in the setup in the configuration but let's say you want to have one route for companies that don't have a company size in the data available. So we can say something like here company size uh let's say does not exist one for we can then add another route right and again we can pass in that same value uh for companies that are bigger than 100 employees

**[65:01]** and another one for companies that are smaller than 10 employees.

**[65:10]** is less than that. Right? So in this case, if we now execute it, you can see that we actually got three routes. In this case, two were routed here. But again, we can now have a separate workflow for each of these uh types of leads. So those three nodes you're going to use quite a lot in practice. Then we have split out and aggregate. Now these are important and a little bit tricky if you're just starting out. But now that we understand data types and data structure, you're going to be able to understand this one quite quick I think. So first a split out node helps you break a list or an array which we talked about before into single items. Now when would we use this is when we want to process each item uh in a list separately. So, for example, in our example, we want to maybe process each of the citations from Perplexity uh to be able to scrape each of those websites uh fully in order to have even more research data, right? So, we cannot just do that right now, right? Because it's inside of an array. So, we can't process them individually if they're inside of an array. So, that's where we use a split out node. So, we're going to change this edit field and we're going to add in that citation, those citations here, right? So we're going to add this in here and we can call it resources. If we execute this step now we have an array here. Right now we want to be able to process each item inside of the array separately. So what we do is we add a split out. Again you can also find it in the data transformation. Right? Split out node. And now we're going to just drag in. And by the way this split out node will only accept arrays. Right? So we're going to add in the resources. And if we execute this now, you'll see that instead of three, we actually got 15 items. Now, why is that? Because it basically processed each item here in the list separately. And we have three total leads. So it did in we have five for each. So in total, it's 15. And now we can actually let's say try to scrape each of these items separately. So a split out we often use together with a loop. Now what does a loop do? It basically allows us to process an item one by one because generally what happens here if for example you see these three items here it will call this API three times after each other. Now if we have very large volume uh items right let's say hundreds or even 20 or 30 and we're doing an API call we're using an action node right usually we have we can hit something with which is called API rate limits meaning if we do too many requests to one uh API or to one software at the same time it's going to run into errors right and therefore for high volume tasks maybe even for this one the 15 items we can use a loop node to basically space out the request we make to the specific software or the application through the API a little bit more. Right? So let's say for example now these citations these resources we want to scrape every website of these citations to get a really comprehensive research report on this lead. Right now we probably don't want to send out requests to scrape all of these pages at the same time. So we can loop over them to space them out a little bit and give it a little bit more time. And this is really important for error uh prevention. So the way we do this is by adding here a loop node which we can also find here in the flow loop over items right and you can do this in batch sizes or we can also loop over five at a time or three at a time but in this case we're going to use it one by one. I'm just going to execute this step. We only have one variable here so it already knows which one to loop over. Right? And here you'll see that now we get two options here. We have the done and the loop. Now here in the loop we can add in all the things we want to do uh with each of these items and once it's done and rerun over this loop then we get to done and we can continue the workflow. So let's say in this case we want to scrape each of these websites right I'm going to cover scraping in detail later in this video but we can just close this loop for now we can delete that and then we can add in a scraper web scraper. Now the easiest way to do web scraping is by a simple HTTP request. And basically we previously used this as an API call, right? But we can also use this to scrape websites. And basically what this does, we can just feed in the URL here. And basically what this does is it just just like you would open a URL here. Uh it will take all the HTML from a website or a URL that you put in here. Right? So it's the simplest way of web scraping. But if there's some websites that have some anti-scraping protection like e-commerce and marketplaces often have this, this won't work, right? So it's the simplest way of web scraping. But for most landing pages, SAS landing pages, blogs, etc., this does work. Now, what I'm going to do here in settings to avoid this uh if there's some error with one specific website, which might happen with this type of scraping method, we don't want the whole automation workflow to stop. Again, I'm going to cover error handling and things like that also uh more in later in this video, but for now, we just want to make sure that it continues even though it might run into an error with one specific website. The way we do that is by going to settings and here on on error, we just click on continue, right? And this is how we make sure that it still continues even though it runs into error. And this is important when you have non-critical workflows. For example, right now it's not critical. If one website is missing and it can't scrape it, it shouldn't stop the entire automation. it could still take the other four and use that as context uh on a lead research. Right? So I can just uh add this and then we can do another nodes which is common for the loop uh because we want to normally space out these requests to API calls especially if we have large volume things. That's why we would use this loop, right? Is to use the wait node to add a little bit of a pause before doing the new request, right? And here we can define the time. Generally, one or two seconds is more than enough, right? And then we have a weight node. And then we bring it back to the loop, right? And basically it's going to run each item separately, these 15 items through the scraper. It's going to wait one second, then do the next one, right? And that's what the loop will do. So if I now execute this workflow, you'll see here we have the three items. Now it's doing a perplexity research. Now we have 50 items. And now it's looping over each one separately and scraping each of these websites separately. And now it's done. You can see we have 16. He has processed 16 items. So lots of data here. Now, one more thing I would want to add because this is raw HTML, right? What you want to do generally with this HTTP request is add uh one node that's going to clean this data a little bit because otherwise we're sending over lots of irrelevant HTML tags, etc. So, generally after this web scraping node, what we want to use is uh a markdown node, right? This one. And this one can convert HTML to markdown, which is basically a cleaner version. So all we can do is drag in the data here, right? And we close the the loop here again, right? We can now rerun it.

**[72:28]** So now it's finished and now we get a lot cleaner as you can see. Right? So we get all of the 15 scraped websites here. Now the last one you want to know here and understand is then the aggregate which of course does the opposite of the split out. Now here we have a good case for example we have all of these scraped websites and now we want to pass that into an AI node that can use that research data to write a personalized LinkedIn message or whatever personalized email anything. Now if we would add an AI node here it would process that AI nodes 15 times with all of these different websites. But we don't want that. We want to feed all the context of all the websites into the AI in one time. So in this case, we'd need to use uh an aggregate node, right? To combine them into one. So here we can go aggregate and we pass in the data here. We execute the step. And now you can see we only get one item instead of 15, right? And for example, now we can pass this all into one AI node, right? To process all of this data at once instead of 15 separate times. So that's it for the split out and aggregate. Uh again, the most common use cases for this is when you want to process each record separately one by one, right? Uh the aggregate when you need a single combined result from many items. So again also we could use for example an aggregate if we don't want to process each lead separately but we want an AI to create a report on uh the quality of the leads for example in this case those are use cases to use for this aggregate. So understanding this item flow here is really important. Again if something went a little bit too quick you can always go here into the N course where you have all the explanation of all the nodes with some setups etc. So you can play around with this a little bit through this course. So now we've covered almost everything you need to know uh in NA to start building your first automations. The big topic uh that's still missing is AI nodes. And this is really where the fun happens and we're really where we can start doing interesting things inside of our automation workflows. So we're going to cover everything from AI workflows to AI agents. So let's dive in. So let's start with nodes you commonly use in AI workflows, right? So the first one is a basic L&M chain and we're also going to learn how to do structured output. Now basically if we want to add AI into our uh uh automation here we have multiple options right I'm just going to delete this part uh as we are not going to use this in this specific scenario so let's say now after this perplexity research we actually want an AI to start writing the per these personalized messages now now we basically have three main options here if we want to add in an AI that starts writing personalized LinkedIn messages so if we click here on AI you see have lots of options for AI integration but the main ones we're going to use is either an AI agent. Uh we can directly work with a node from the language model providers like Enthropic, Google Gemini or OpenAI and we can use a basic L&M chain. Now in this case we're using a basic N&M chain and the difference between this one and for example using uh an open AI node is that in the basic L&M chain we can still switch providers. So we can use any L&M in this basic L&M chain. We can use Google, we can use entropic, we can use OpenAI etc which I generally recommend. So we can test around and play around a little bit with different models and see which one work best. So in this case I'll just show you an example. If we choose open AI here we can uh have different options too like an assistant which is basically like an AI agent which I don't recommend using. I recommend using the AI agent node which we'll go over in a second. So in this case we're going to go let's say with messenger model. Now the difference here is that in this case we can only use open AI. Now, in general, when using AI, you want to focus your workflow on having each AI node focused on one specific task. This is really important to keep your workflow as reliable and consistent as possible. AI in general is best when we give reduce the responsibility. When we give multiple tasks to an AI, that's where AI generally starts to hallucinate more and become less reliable. So, in when we're adding AI into these workflows, we really want to build granular and make sure that each AI step is responsible for one specific task. Now in this case we can go get away with one uh AI node because all it has to do is write these linking messages. In this case we go with the basic event and if we open this up you can see that automatically it will be connected here. The source for prompt is connected to chat trigger node. In this case we don't have a chat trigger. This is more relevant for AI agent use cases. So in this case we're going to change this to define below. And you can see now we can define the prompt for this basic NLM chain. Now, generally the way we set this up because in this case, of course, we're going to pass in variables because we want to pass in the research data from that previous node. And by the way, I deleted one too many here. We're going to add in that edit field node. And we're going to just make sure that we get the research data here, right? And that's what we're going to pass into that m. Right? So we connect this and now we can feed in the research data. Now besides the research data, we probably also want to pass in the name of the lead and maybe the company name so that an M has context when writing this LinkedIn message. So what we generally do is the variables we add in this top prompt here. So we can go with lead name and then the prompt the actual prompt on how to write these messages we're going to do uh down here below. So in the lead name, we're just going to go to the air table node. Going to add in a name and the last name. Then we're going to add in the company name and of course the research data which you can use to write personalized LinkedIn messages. So research data

**[78:21]** Now here we see another option which is require specific output format which we're going to go over in a second but first we're going to do and make the prompt. So here in general what we do is we select system prompt and here's where we actually instruct the system on how to write these messages. Now generally the way I like to do this is by using a tool called prompt cowboy which is by Henry a friend of mine which is basically a tool that turns lazy prompts into great ones. So, it's a really easy way to build good prompts really fast. Now, why is this important? Because when designing these AI workflows, prompting becomes far more important than prompting inside of CHPT because in this case, we want uh this system to generate good LinkedIn messages each time this runs. We can't go back and forth just like we do with CHPT. We don't have that flexibility. And therefore prompt engineering and writing good prompts becomes far more important if you want this system to uh perform consistently and reliably. Right? So that's why I highly recommend using these kinds of tools to really guide write good prompts. And this is really what this tool does. It has embedded uh a lot of the best practices for writing good prompts. So generally the way I approach this to do this fast is I have a tool called whisper flow that allows me to talk into my computer which helps me speed up the writing a lot more. But generally I just give overall sort of instructions on what this prompt needs to include and then uh I let the the the tool do the rest basically. So in this case I could say something like I want you to write a prompt uh that generates three LinkedIn outreach messages to a potential lead. The goal of these messages is to eventually try and get them on a call for my services. It's very important to follow the following guidelines. Message one should never pitch any services. It should just focus on trying to get the connection request. So, it has to add a personalized line and a request for a connection. Also, the first message cannot be longer than 200 characters. That is a hard rule. The second message should focus on asking the potential lead a question about the specific sort of offer or service I offer. it shouldn't pitch my services yet. And the third message can soft pitch my services um to the potential lead. It's very important to add these instructions about the specific messages into the prompt. Now, some context on me and my business where we're doing the outreach from is I am Ben Plansferno. I uh run Ben Aai where we help companies automate uh their processes both in sales, marketing and operations through AI automation solutions. We also sell an AI SEO system that help companies rank better in Google and in AI search results. It is very important to have a casual tone of voice. Don't be too formal. Basically talk to a colleague. Now that's what whisper flow does. I can just sort of talk into it like that. And now we get that written now. And now we can just uh select here and it will write this prompt a little bit more structured and use best practices. So you can see your Ben SP founder event company. Uhhuh. Generate three sequential LinkedIn outreach messages designed to strategically connect with potentially uh convert a potential lead following strict guidelines for each message content and approach. objective knowledge right so this is a pretty good job so you can see it structured it a lot better already now generally you have to read this a bit generally I edit some part of this then I try it out and then based on the output I start iterating and improving a bit but in my experience this is the fastest way to sort of get good prompts right in the end it is an iter iterative process right you rarely have it perfect on the first try but generally in my experience this is a really fast way to build good prompts now important when you're writing content is adding in examples. Examples might be the uh most important thing to get the tone of voice right. So that's what I would definitely do in this one and then add in a line at the end that says almost mimic the tone of voice of the examples. For now, we're just going to copy this and we're going to go back to the workflow and we're just going to add this here. If we click this thing in the bottom bottom right corner, we get a little bit more space for our prompt. We can also read it in more detail. Uh but we're just going to start with this for now. And then all we're missing here is to add in a model. Now again, you can go with any language model here. In this case, we're first going to go with OpenAI. And this is the same as with the action nodes. We have to add in our credentials, right? We need an API key from OpenAI. Now, mine is already connected. If you don't know it yet, you just go here, right? And you have to add in your API key. Now, where do you find it from OpenAI? You go to platform.opai.com. You can loging in with your normal account and if you go here to your settings, you'll find an option here of API keys. You can create a new key here. Let's say test five and you can create a new secret key. Now, before doing this, you do need to have some credits onto your OpenAI account. So, you can go here to billing, upload $5, whatever you want, and then you can actually start using OpenAI in the API. So, we can copy that one. We can paste it in here. And then we have the connection set up. And then you can see that here we can choose the models. Now in general you should play around also a little bit with the models. Now depending on the use case sometimes reasoning models are better, sometimes traditional models are better. Now I generally tend to play around a bit. GPT5 came out uh uh recently. So I've been trying GPT5 a bit but when I was building that original workflow I actually noticed that GPT40 produced better outputs and is of course a little bit cheaper. Now why is that? In general, what I've noticed is if uh you try to write something, these non-reasoning models, you they follow your prompt guidelines a lot more. So, if you have lots of examples on following the the right tone of voice, etc., which is really important in these personalized LinkedIn outreach messages, then uh what I've noticed is long structured prompts with non-reasoning models generally perform a little bit better than the reasoning models because the reasoning models in my experience are a bit more creative themselves. So, if we want to give them strict guidelines on tone of voice, etc., it sometimes results in uh not so good copy in my experience. But of course the big upside of reasoning models for other tasks is they are far smarter and they can uh do much more complex things right but in this case we're giving it lots of guidelines so we can get away with GPT40. Now in general what you can also do is just play around with other models like Google Gemini Entropic. Entropic can be very good too at copyrightiting right content etc. So that's what I probably do when I'm testing this in production. I would try it out with different models too. Now, if you don't want to get API keys for all of these different models, you can also use a tool called Open Router. And Open Router basically allows you to create one account on Open Router that has all of the large language models integrated into this one. So, then we can just have one tool here where we can experiment with all of these. So, that could definitely be an interesting one to to check out. Now, for now, we're using the OpenAI one. And uh now we can actually run this Let's see what happens. Now, an important part I missed in this specific prompt is giving it examples, right? That's why I don't expect this output to be really good, right? So, we can see here, hey Ben, I saw your revolutionizing AI automation in business. Your no code approach is fascinating. Excited to connect and exchange insights on AIdriven solutions. Not really bad, but not really the tone of voice I would be using. I've noticed it's a hot topic lately, right? Those kinds of words I wouldn't use in outreach. So what I would actually do is now add in lots of examples of good outreach messages and that will probably adjust it. Now in my previous one that I already built out, I already iterated on that prompt. So I'm just going to use that prompt for now and copy and paste it. Copy and paste it. So that's this one. Again, if you want to read these prompts in detail, you can just uh download the template of the original workflow, right? Which will again be available on the free resources. So I'm just going to add in that one. going to set up the prompt. Now, as you can see, the way we get this back is in one large text file. Now, of course, what we want to do later, right after this, is upload each of these uh LinkedIn messages into different columns. Now, that won't work if we have this large text file. So, what we can do here in the basic LM chain, which in practice you're going to use quite a lot, is require specific output format. Now if we select this you can see that besides the model we have a new option here to add which is an output parser. Now this is really important to understand. Basically what we do with this structured output parser which we're going to use is we can hardcode in or uh tell the AI exactly which data structure it has to put the output in. Now we can do this from a JSON example where we can write in a JSON ourselves of an example output or we can generate an entire uh JSON schema. Now, if you want to do that through the schema, the easiest way to do it is just to go to chat GPT, describe exactly what kind of output structure you want and then uh OpenAI or CHTP will do it for you. You copy and paste it in, right? You just describe to Chat GPT that you want a JSON schema and you describe how you want your output format to be. Now, in this case, I'm going to generate it from a JSON example because it's going to be a simple one. All I want is message one, message two, and message three separated. So, and of course each output is going to be a string because it's going to be a text, right? So, basically I can just delete this and copy it three times. All right, we have message two separated by a comma and then we have to add in one more which is message three.

**[88:17]** Right? And the last one is always without a comma. Right? Now, this is the JSON example. Right? And we can go even further and go on the autofix format. And this is basically what you'll see happening is we get another option here. And we can connect this to the same OpenAI node. Basically what this does the autofix most of the time when we don't do this it already does it in the right way. But with this autofix we basically force another model to check if the output was correct and if not he will autofix it automatically. So this was basically make sure that 100% of the time it will output it in this format. So if I now rerun this, you'll see that it used the structured output parser and now we get the three messages separated and probably the output is a little bit better. Hi Ben, I recently saw how Beni is using no code tools to drive AI first strategies. Impressive work transforming businesses. As a founder yourself, I'm curious how you've seen AI change sales outreach strategies. Got any insights from your work at Beni? So you can see it improved quite a lot already because I've added in this new prompt with examples. Now now we get three outputs and now the last step is really to just update our CRM in air table with the output. Now in this case we go to air table and we can select update record again we can go here to select the base select the table and then what you'll see happen here is columns to match on. Now what does this mean? It basically means it because there's going to be three flows right for all the three leads. It's asking which uh ID should we identify to know which row to update. Now in this case it automatically filled out ID and basically what we do is we just go back to this previous air table node and there you'll see for each of the rows exported we get a row ID meaning if we just feed this in then this node this update record node knows exactly if we fill out this new data with the messages which of the rows to update the data for right so then you can see we get all the all the fields first name last name company name etc now all of these fields we already have in the database. They already filled out. So instead of dragging them all here, we can just delete them. And if we delete them here, basically it means that they won't be changed. And as they're already filled out, we're good to go there. So all we want to update here is the LinkedIn messages. And what we do then is we just drag these in. Message one, message two, and message three. And that's why we used the structured output parser because of course if we got one blob of blob of text, we couldn't do this uh separately. So that's it. Then we can execute the step and you'll see if we go back here now they're updated right for all of the three leads. Now just to cover everything you need to know with AI nodes we go back to the presentation and structured output we have covered AI models we have covered. Then we have another AI feature in uh NAN which is called human in a loop. So let's say we actually have another node here that actually sends the LinkedIn message to uh to a lead. But we don't want to do that automatically. We do want to check if the message it wrote is actually good. Now this might not be the best example of this, but you can imagine there are many examples where it's very good as a human to check if what the AI did is actually good before executing on the task or sending it out to a lead etc. So the way we can do that easily in NAN is by adding in human in the loop. Now we add human in the loop a lot through air table. Of course you can do that through another software too but you also have direct uh uh options for this in naden and basically here you see the human in the loop option and we can do this human in the loop in multiple different software. So we can use it uh through discord, gmail, uh slack, telegram, WhatsApp business. And the way this works is basically we can add in a Gmail node here. Again, we'd have to connect our Gmail account, uh, which is just basically a login, right? Mine is already connected here. And what will happen is basically it stops the workflow. It will send me an email with the data, ask me in the email if everything's good, and once I approve in the email, then it will actually continue the workflow. So, it can be very useful in these automations. So, for example, can try this out. Approval required, right? We can add in the LinkedIn messages. Here are the messages.

**[92:47]** And here you can also decide uh what you want to do, right? You can uh send and wait for response in this case, right? Response type. You can have free text also where user uh can submit a response via form. So you can actually change things. In this case, we're just going to do approval. And once we now execute this step, you can see also in the workflow that it's little clock here. It's basically waiting until it takes the next step. So if I go and open my Gmail, open my Benai, you can see now we got an email here with approval required. And here are the messages. And then we can just decide to approve. And in this case, you can see now it actually made the check mark. cool little feature to work with AI in uh in NAND but in general we do this through uh air table which I'm going to show you later in this video when we're building AI products because human in the loop is really important when we're building AI products now the next part we have to understand is AI agents right and as I said uh at all the way at the beginning of this presentation is we basically have two main types of use cases for AI agents one is the sort of the chatbot or assistant use case uh which I'm not going to cover too much in depth in this video because frankly we haven't really built them out that much for clients in our AI agency because generally AI chat bots are not as valuable as some of these sales systems and marketing systems that we generally build for clients. Of course, if your focus is on chatbots, uh there are definitely very interesting use cases you can build with this. But in general, we focus on AI agents as being part of uh the AI automation workflow and being in charge of one specific action generally for research tasks. So again, if you want to learn more about the customerf facing or the chatbot use case of AI agents, there are many tutorials on the internet, I also have a video on my channel that covers a WhatsApp agent, an uh Instagram agent and a Facebook agent in one. So if you're interested in that use case, you can check out that tutorial. But in this tutorial, I focus it more on uh these sales and marketing use cases and building AI products eventually. So let's say in our original flow, we don't want this no to just be a complexity research. We want to go and really do deep research. That's where we can use an AI agent. And that's really one of the main use cases we use AI agents in our in our workflows is to do deep research because uh what we can do with an AI agent for example if we replace this node here with an AI agent is we can uh give it access to multiple tools not just perplexity. So we can give it access to a web scraper maybe even a LinkedIn scraper so it can reference old LinkedIn post of them uh things like that. So if I add in an AI agent here in this case for example we can uh just give it a web scraper and and a perplexity research. So the way we do that is by setting up this AI agent here AI agent node and as you can see it's quite similar to the basic M chain but we have two more options which is memory and tool. Now memory is just for the AI agent to remember past conversations right which is more for the use case again of chat bots. Now, if you want to do that use case, you can really easily add memory to this AI agent by clicking here simple memory, which is basically memory that's stored inside of NAN. And if you really want to build production ready AI agents, you probably need a more um scalable database, something like Postgress uh or or something else, right? So, in this case, we don't really need memory. Then, we can add a chat model. Now, uh again, we can decide which one we want to use. We can use open router if we want to experiment with different models. But in this case, we're going to use open AI. Now, in general, what I've noticed for AI agents, reasoning models, especially for these research tasks, can be far better than uh non-reasoning models. So, in this case, I'm going to use GPT5 GP5 and then we can add tools. Now tools, you can see we have multiple options. First, we can also call another NAN workflow. So let's say we have built an entire AI automation. We can actually call that entire automation as a tool in NAND. Now for this specific use case, we're not going to use it. We can also use a code tool which we're not going to use. We can use an HTTP request tool to basically make an API call to any software or we can just choose from all the softwares natively integrated just like the action nodes. Then we also have an option for vector stores more again for the use case of chatbots. When you want to give your agent access to a large uh uh corpus of data or context for example about your business or things like that then you can start using vector stores uh like superbase or postgress to store all of that data that your AI agent can use to answer questions for example. But in this case again it's not very relevant for our specific use case. So we're going to just stick to a web scraper. So again we can just add in a scraper here. Now in the description it is important to describe what this tool does because this is basically what your AI agent will read and therefore know what this tool can do. And sometimes you can also instruct in on how to actually use this tool. So in this case you can say this tool use this tool to scrape the website of uh the company. Now method of course is get and then you see here because this is a tool of an AI agent we see another option here which is this this this thing here I don't know how to describe it but it's basically this allows uh us to say that the AI agent is can fill this out themselves because of course the AI agent will have to put in different links here we can't define this or hardcode it in right so we can just use that and the AI agent will fill it out now again important here we can add a description and basically tell the AI agent what to fill out in this field so we can say at use this use the URL of the company in this field. Now that's really all we need to do for the setup in this tool. And then of course we're also going to add in a perplexity tool. Now think perplexity actually just has a native integration here with AI agent. So we can just use the perplexity tool here. And again here we can just set up the configuration. So in this case, we're going to set automatically message and model, right? We're going to choose the model. So let's do sonar pro. And then we define uh the text, right? What this has to search for. So again, we're going to let our AI agent decide. He has the flexibility to type into perplexity whatever he wants to do deep research on. So we just click this button defined automatically by the model, right? And again, we can describe what to fill out. use a query that performs uh deep research uh on this lead and this company. Uh and you can even go very specific here, right? You can say like uh make sure it uh um researchers funding data funding rounds uh decision maker data etc. So you can get very specific there. And then we lastly here we can decide simplify output which you generally want to do with tools. And basically it means it cleans up the data before sending the output back to the agent. We do that we do that too for this one optimize response right and we can go uh with text here. So now we have added the tools and of course now we have to set up our AI agent. Now again it's automatically connected to a chat trigger node which we don't have. So we go define below and here we do the same thing right we have the prompt the user message where we can pass in the variables. Now in this case we're going to pass in a few more variables. We're going to pass in the lead name the company name but also of course the company URL. I think those for now would be good enough to do deep research on. So we go at this

**[100:45]** last name. Then we have company name, company URL, which of course you can use to scrape. Now, the big difference with this and setting it up without an AI agent is an AI agent can actually use these tools multiple times to really do deep research, right? So now we've added in the variables and now of course we have to add in a prompt. So what we do here is we go system message and here we can type in the system prompt. Right now again we're going to go to prompt cowboy and actually in prompt cowboy we also have an option for specifically optimized um agent prompt. So if we go and do this drop down here and we go to custom GPT agent prompt you'll design a prompt that's specialized or optimized for AI agents. I can say write a prompt for an AI agent that has to do deep research on a lead and a lead company. It has access to two tools which is a web scraper tool and the perplexity research tool. Make sure it uses these tools multiple times to really do deep research on this lead and this company. The research data should be relevant in order for a subsequent AI model to write personalized LinkedIn outreach messages to this potential lead. So we can just describe it quickly and then again let prompt cowboy do it do its work and write a good structured prompt for our AI agent.

**[102:19]** Now this we're going to not use output requirement because in this case we don't really need structured output. So we copy this prompt going back to N. We paste it in. Now probably this output requirements structured research report clearly categorized insights. And if you really want your AI agent to do deep research where you can stay in these prompts is uh for example use minimum five tools in your research. Right? By the way, a good tip to have is when you're testing out and improving your cont when when building out these workflows, an easy way to add instructions or things you see going wrong, etc., is by adding another header here with notes and then adding any important rules here in the notes because generally AIS take uh context from the beginning or all the way at the end of the prompt more into account than in the middle of the prompt. So, if you add this to the end, generally you'll see it improve right away. So use a minimum of five tool requests for your research.

**[103:27]** So now we have our AI agent set up and of course this has not run yet. So this don't doesn't know what data to expect. So first we're going to go and delete this because we can basically pass on the data directly to the basic chain. But in order for our system for our basic AM chain to know what data I can expect from the from the AI agent, we have to execute the workflow and test the workflow first. So let's just test it out. See what happens. Now this can take a while because we're using a reasoning model with deep research. So it can literally take minutes before it uh finishes this research. So you can see it's using the opening chat model and now it should be using the tools. So you can see it's using perplexity.

**[104:11]** I'll speed this up quickly because you can see it does very deep research. So now finish the workflow. I'm going to delete this human in the loop here. Uh but what happened here of course because I just added the AI agent into the node is we didn't actually pass the variable into the next one. So if I open this one right now, you'll see that the this variable is red because of course this was first with the edit or set field node. So now we of course have to replace that with the actual AI agent outputs, right? And you can see that the AI agent did deep research, right? And gave us a really deep overview of all of these leads, right? And now by the way, if we want to test this workflow uh from after the AI engine, so this doesn't have to run again, we can use a feature which is called pin data, right? And basically we just pin the output data of each of these nodes. And once we do that with this AI agent and we click on execute workflow basically will run from here. The rest is already pinned. So now it will actually take that output data into this one and we can actually see the results. So fellow advocate for AI automation I admire work we're doing at we you're doing at Benai. Let's connect. Yes. So of course this is not the best example because this is actually me. But the point of this is using an AI agent here uh for research purposes can really enhance the amount of research it does. Right. And we for example also use this in our SEO system uh which we of course sell to to clients which is this entire workflow. Now don't get overwhelmed here. It basically includes all the nodes you've already seen but it's just very large and we started with like 20% here. Uh but you can see we use these AI agent for deep research purposes. For example, this one does deep research on competitors content etc. Uh which we'll use to outrank competitors things like this. So that's generally how we use AI agents. I'll show you a quick example of how we use an AI agent without this. If I can just copy this specific workflow and just add a new and just add a new workflow here. Quickly, I can show you quickly how we can use an AI agent as an assistant or a chatbot. So, we can just use the tra chat trigger node, right? Then we add in that AI agent. Now, I can just open the chat here. Now, I can say hi. And you see my AI agent's actually responding. Hello, how can I assist you today with your research needs? Right? Of course, now we want to have to add in memory because it needs to remember the past conversation is if I say hello now again, right? It don't it doesn't remember that it said this before and that I said already, hi, right? So, we add in a simple memory here. Right? Now it actually remembers my name is Ben. Hi Ben, I can help with gathering information. Now I can ask what is my name? And now it actually name knows your name is Ben. Right. And of course now I can say hey please do research on uh Ben fans. Right. And now I actually use these tools as you can see to actually do research. And of course we can launch this on WhatsApp, on Instagram, on uh any tool which can be interesting for uh appointment setter purposes, chatbot, customer support um purposes, etc. Uh again, if you want to see that in more detail, I have a full tutorial on that on my YouTube channel. So you can see now here I did some research, etc. But just give you a quick idea of also how you can use agent. By the way, this uh this one you can also make publicly available. So you can uh just get a link here, right? And once we put this in production, right, and put this on active now, we can open this. We basically get a little chat here. So, we can go, "Hi there, my name is Ben." And basically, we have a little bit of a a quick chatbot here. But, uh, yeah, it's not the nicest UI. I recommend uh you can also build a quick front end or user interface for your AI agent on on tools like Lovable, etc., or Clot Code, which I also have a tutorial on on my YouTube uh channel. Now, let's go back here. Now one more interesting thing that Nadan has just added um is here the option to actually add in another agent as a tool meaning we can build multi- aent systems very easily. So we can see here AI agent tool we can basically just call another AI agent from another AI agent right. So we can go even more complex. So let's say this AI agent has access to all social media scrapers to scrape all social media from this person and the original agent has only a web scraper. you can work together to do even more deep research. Now, in general, you don't really use this sort of setup that often uh so I wouldn't worry about it too much for now, but it is an interesting uh use case. It makes it really easy to build these multi- aent systems. Now, lastly, you can also add in MCP right now, right, as a tool basically, and you can see it here, MCP client tool. And here we can basically set up our own uh um we can call our own MCP. So we can create our own MCPS in uh NADN which again I'm going to show you here very quickly because the use cases for this for production ready workflows are not that uh often yet. So basically what we can do is set up an MCP server trigger. Now this server trigger we can then call from the AI agent. Now what this does is we can basically just add in all the tools we want. So we let's say we have 10 different actions in air table. We can connect all of these actions like update a record uh uh delete a record um update multiple records etc. All different actions we can take. We can add them all here. Then we get a link here as you can see again a test URL and a production URL. We can use that link then to call in our AI agent MCP client and use that endpoint and then basically our AI agent will automatically have access to all of the tools of air table for example. Right? So it's an easy way if we can make very complex systems. It's an easy way to uh reduce complexity uh for the AI agent and therefore it will also increase the reliability of these AI agents. Now another use case for this MCP trigger is we can actually connect this to Claude. So Claude uh also has access to all of these tools inside of Claude. So you can actually use your software and again I have a full video uh on my YouTube channel too on how to set this up with cloud than MCP. I'm not covering it in this video because it's not very much a sellable setup. It's more a use case that really can help you uh have a better assistant with cloud that can actually interact with your softwares. So if you're interested in that again I have a YouTube video on that uh on my YouTube channel. So that's it for MCPS and really we've now covered all AI nodes and all essential nodes in Nad. Now there are few more essential skills you really need to know in NAN to start building automations and the first one is scraping. Now scraping you got to use almost always in these automation platforms because in general we're trying to get as much context into our system in order for AI to take action on that context. So that's why generally we try to scrape uh social media to get context for writing uh uh whatever social media posts uh we try to scrape LinkedIn and other data sources to get more lead uh information just like in our example. But we use web scraping a lot to get more context from specific websites. So it is really important to understand. So we basically have two types of scraping. We have web scraping and we have social media scraping. Now why have I separated this? Because web scraping we generally do a bit different than social media scraping. Web scraping the first option I've already showed you which is the HTTP request. All right, which is the easiest and the cheapest way to scrape, right? Because we can just use HTTP request and that's it. Now generally we want to use the markdown to clean that HTML data up before we pass it into an AI node or any other node. Now sometimes uh websites have some protection or some way they have built their website that it doesn't work with an HTTP request. So the other option there you have and I highly recommend is to use fire crawl. Now firecrawl is uh a web scraper with basically all the options. Here we go. Firecrawl uh for web scraping right it's really easy to set up quite cheap to run and they actually have a community node here available. So with fire crawl you will see I can show you quickly in the documentation we have multiple ways of web scraping right we can scrape here just a simple page right and again you already know now how to set this up right because you can just go to curl copy and paste it into the HTTP request and you'll have your API call to firecrawl set up right but we have scrape we have crawl and crawl is different than scraping because crawling basically scrapes all the uh pages of a website. So instead of just one URL, it'll scrape everything which can take quite a while and is of course a little bit more expensive but for some use cases it's definitely interesting. Uh then you also have map where you can uh crawl sorry scrape the site map. So you can uh sort of scrape all the URLs from a company. Let's say you want specifically the contact page. Scrape the entire site map and then identify maybe with an AI note the right page to scrape for contact information. Right? That could be a use case for that. And we also have search where you can uh even add in a search query to find specific information on a website. So highly recommend checking out firecrawl. Now there's another type of website which is really has heavy protected anti-scraping me measures which generally are like uh e-commerce websites or marketplaces that have some value uh in their marketplace, right? So they make it really hard for us to scrape. Now the best one for hard to scrape websites which is Scrapfly. In my experience, this is one of the best scrapers out there for hard to uh hard to scrape websites. So, that's all you really need to know for web scraping. By the way, Perplexity I we use constantly. You can you can already see it because instead of uh separately scraping things, Perplexity basically takes some context from different sources already uh instead of us having to scrape each of these sources separately. So, Perplexity is an amazing way to to to get that same sort of output as some of these scrapers do. Now, for social media scraping, really you have to know two platforms, and those are Appify and Rapid API. And Appify and Rapid API, if you don't know them yet, they're basically marketplaces full of scrapers specifically for social media. Also, we have some web scraping uh tools available, but basically those are people that have built their own scrapers for specific platforms. Social media platforms are uh always really hard to to to scrape with normal scrapers. That's why we need uh specialized scrapers which we have on these platforms ampify and rapid API. So you can see we have Tik Tok scraping, Google map scraping, Instagram scraping, uh Amazon, anything you can imagine we can do from here. And the same the case for rapid API. It's similar concept, right? It's just a marketplace full of uh scrapers. So if you need to scrape social medias, LinkedIn, Instagram, uh any one you can imagine, check out these platforms. Again, I have links in the description below too. There you can just find the API information and again you can just copy the curl and you already know how to set it up. Now apply actually has a community node here in uh N2. So if we go back to the original workflow and we add in an appy you'll see it actually appears. I think it's actually a native one now but uh we can just run this here. So this is a really important one to know. And the second one is rapid API where we actually have to set it up custom. Now that's it really all you need for for scraping. Um when you know these tools you can really do anything you want. Now the last thing we have to learn is and is not to be forgotten and is often forgotten is how to actually efficiently debug and error handle. Now for debugging there are three things you want to keep in mind. First the pinning data is a really uh important one to keep in mind. Just like I showed right now, instead of running the whole AI agent thing again, I can just pin the data, right? And make sure uh that it only runs from here. So we don't constantly have to rerun this, right? So pinning data is a very important one to know for debugging. Second, of course, we go here to executions. And what's important to understand here is that as long as our automation workflow is inactive here, we actually see this all happening here, right? And we can sort of debug in the in the editor. But as soon as this automation is actually live, then that changes, right? Because as soon as this is actually live, it won't show us here the automation actually running. The only way we can see past automations that have run is in the execution tab. So once you've put this live for a client or for yourself, right, the way you have to debug is through this execution step. So you can go here too and see all the errors, right? All right. And you can just check that data here. And what you can do is actually uh click here on debug in editor. And then you can actually save the data from that specific execution and debug it with that specific data. Right? So it will basically pin that data to your editor. Now keep in mind debugging is part of the workflow. Uh you're going to run into issues all the time, but is part of the learning process. Right? So don't worry about it. Uh and you'll get better better and better at it and faster and faster at it. So don't get frustrated. Just see it as part of the learning process because once you've seen some errors more and more, you'll know how to solve them instant. Now the second important thing you really have to learn is error handling, right? Especially when you're going to build out these solutions for clients, right? And really run them in production. Now there are few things you want to keep in mind with uh error handling. Now first of all what you always want to do is any action nodes or API nodes generally you want to go and get in the habit of going to the settings and always add this retry on fail and switch this on. Now why is this? What is this do? Why is this? First of all because API calls softwares they just run into errors sometimes. Uh we are dependent on their servers etc. and some things just go wrong in software sometimes and this is one of the most common errors you'll see happening in production is just an API call failing because of the software. Now an easy way to solve this is to retry on fail. And basically what this does is it just tries again if it fails. And here we can define how many tries generally three is enough and how long to wait between tries. So in this case 10 seconds is usually more than enough. So only this will basically solve 99% or 90% of your API call errors, right? Which is one of the most common ones. So you just want to get in the habit of putting all your uh software nodes on that setting, right? So that's the first one. Now, the second thing you want to do is make sure that non-critical workflows like scrapers and things like that when they're non-critical, we want to add another setting in the settings in the settings of those nodes and go here and change on error to continue. Right? And we use this before what I showed you before. So, if a scraping fails, we don't want the whole automation to stop. We want it to continue, right? So for non-critical workflows where the information is not it doesn't have to be 100% correct always just make sure to choose continue here. Now another option here is if it is a critical workflow and it can absolutely not fail uh then we can use the stop workflow or we can use continue using error output right and what you'll see happen here with an error output is we actually get another flow. So if this produces an error we can do something else and what we can do here for example is to stop an error. So you can throw an error in a workplace and you can say here for example air table error. Now in reality I don't use this one that often because instead of this what I do especially if I run this for a client it is really important that we get notified as soon as an error occurs otherwise a workflow can keep running and running into errors continuously. So we want to know when an error happens especially on a client's account, right? So the best way to do this is by is by going here on the three dots and here we can go to settings and here you'll see we have an option of error workflow. Now how does this work? We can basically set up a new automation. So, I'm just going to replace this one and add and I just recommend doing this in general have an error trigger here. And this error trigger basically gets triggered as soon as this automation or any automation in your your account or your customer account runs into an error. And what you can do here is build a separate automation for this. And generally what you want to do is just send yourself an email or notify you on whatever uh message channel is best for you like Slack etc. Generally I set it up in Slack. But here for example we can set it up in Gmail. We can just go on send a message right now. Of course, we have don't have input data, but you get the concept, right? You can just send yourself uh a message. You can also get the data on which workflow run into an error. And then you're just going to dive in, make sure your customer's automation runs properly. So, highly recommend this. These are just important things to keep in mind, right? So, non-critical workflows, use continue, right? Especially if it's a errorprone thing like scraping. Uh second, always for any API call, make sure you switch on the retry on fail. And third, make sure you get notified, especially if you're building uh for clients through the error trigger uh with a notification to email or Slack wherever you want. So those are three important things to keep in mind. Uh and by the way, I missed that, but that workflow you created. So let's call this error notification, right, will then appear here. And here you can now decide error notification. And any error that will run inside of this automation will then trigger that automation, right? And you can basically set that up for all the different automations. You can all refer back to this error notification uh trigger. So generally good practice. That's really the 8020 of NAD. With these skills and these nodes, you will be able to build out almost anything. Our entire SEO system, as you can see here, doesn't consist of any more nodes than what you've already seen. So now is really about learning how to design these AI systems and AI products. So, I'll dive into very quickly how these AI products are set up, but we're going to learn this in more detail by the end of this video and going to build one from scratch. So, how do you transform these custom automations into AI products? Now, there are really four key things you want to keep in mind there. First, uh you want to switch this from a custom automation to a productized one. Now, the first step to doing that is if we think about our automation, our original automation here, right? We this is a custom automation. Now, why is that? because it's specifically built to do outreach from me from Ben. But of course, if we want to make this reusable and resetable for multiple customers, we we have to make that a variable, the customer. So, of course, in this one, we give it context in the prompt on uh me, right, and my business right here, Beni. Now, this of course has to become a variable in order for this to be resetable and reusable by multiple companies. Again, you're going to learn later in this video how to do that. But the second important thing is of course to add in a front end right where the user can actually use this system in a user-friendly way. Now the way we generally do that is by setting it up on air table. So here's an example actually of a system we built with this small automation you saw uh is actually part of a larger workflow which we call a LinkedIn BDR agent. And here for example a new project can be set up for a new client. It will automatically generate a context on that client. It can do cold outbound. It can do warm outreach. It can do uh inbox management, but we built this in a quick uh front end so the user can actually use this. And again, we're going to learn how to build up these front ends of these user interfaces in Air Table by the end of this video. Then lastly, what we generally do is break up the workflow in small steps and add lots of human in the loop. Now, we have learned that if you're trying to sell AI products, you really need lots of human in the loop. Um, that's first of all what customers want and that's really how you make these systems especially large end to-end systems actually production ready and usable for people because if we're trying to automate this entire large workflow like our SEO one in one go it's going to be very error errorprone if some small variation goes wrong in the beginning it will have huge consequences at the end. So that's why it's far better to break them up into small tasks and after each step a human checks if everything's good, decides on what to take action on and then uh execute on the next workflow. So that's an important one and then generally what we do is we use a web hook with a switch node uh to break up all these. So as you can see here at the beginning all we have is a web hook that gets triggered from an air table action and these are all the different actions that can trigger different workflows. So now you should understand the setup here. Now again later I'm going to dive into this in much more detail and we're going to build an entire AI product with this infrastructure from scratch. Now I just wanted to show you this because again this LinkedIn BD uh this LinkedIn system we just built is actually sort of part of uh one entire system that we built which is the LinkedIn BDR agent which does the actual scraping which does the outreach which does the inbox management for LinkedIn and basically use all the nodes that you've learned today. Right? So I just wanted to show you that you can really take this to the next level and build AI products once you understand these essential nodes. You don't need to know much more in NAN in order for you to build these AI products. It's much more about understanding the infrastructure of how to design these AI products. So hopefully that got you a bit more familiar with some of the concepts in NAN and help you understand better what it actually takes to build out an entire project. So the next step is really to start thinking of some useful automations you can build for yourself. maybe for a friend of yours or a company you work for to really get the practice you need to master this skill. Now, the quickest way to fail here is by just diving into building straight away. Planning and scoping is an essential part of building AI automation projects. Knowing how to plan and scope these projects is going to save you a lot of time when you're actually building. So, in the next part, we'll cover exactly what to keep in mind and how to properly plan new automation projects for yourself, but even for potential customers. Before starting a quick disclaimer, this is not the only way to plan and deliver AI automation systems. This is just what works for me and my team and hopefully can help you. And second of all, I'm going to focus this framework on uh delivering uh automation systems to clients. Now, even if you're not doing this for clients or not doing it for clients yet and you're just trying to build your own automation systems, I think this framework will really help you understand how to um first of all plan out these projects and second of all improve the outcome of your automation systems. And lastly, this framework can really be applied to any of the the no code uh automation softwares whether you work on on naden relevanceci uh make.com or or any other this uh should be helpful for any of these. Now, as I said before, most people jump straight into step three, the development phase, uh, which is understandable. It's the most exciting one, but in my experience, and I've learned the hard way, it is really important uh, to cover those first two steps first. Right? So, first we have uh, the project scoping. And in the project scoping, we're really trying to get clarity first of all on the specific uh, problem we're trying to solve or uh, the need we're trying to fulfill, right? Because in the end, any of these automation systems, that's what we're trying to do, right? We're trying to resolve either business or personal need or or problem right and we also want to get clarity of course on the objectives the specific requirements and the metrics uh for the for the automations. Then from there we can uh dive into the system design and in this part we're actually going to design and establish a process right because very rarely are we actually automating an existing perfectly well- definfined process or system. uh most of the time we have to establish and design the process in the first place and then we can actually automate it right most businesses are very messy and don't have well- definfined processes in place so once we have done that we can actually make a road map and uh with that a proposal and from there we actually dive into the development where we build uh test debug step by step and implement error handling at the end and then lastly of course we deploy and optimize again rarely uh are these automation systems perfectly optimized for business at the first try which is perfectly fine but we do have to uh plan it into our process and iterate and improve based on real world usage and feedback. So let me go through them one by one so you get a better idea. So in the project scoping what we're really trying to do is get all the necessary information to be able to design a system and to judge the feasibility of the project right is it actually doable now key here is to mention that we're only trying to get the necessary information not all information right automation projects can get very complex very quickly and normally lots of little details and and feedback and and extra information is necessary from clients to be able to scope out project 100%. Right? We're not trying to do that. We're only trying to get the necessary information to be able to design the system and to judge the feasibility. Now, we usually try to do that in maximum the first two meetings. And from there, we send the proposal and wait for client payment and all the extra details we'll figure out in the onboarding call, which is the first call after payment and even during uh client fulfillment. Now, why do we do this? Because again as I said automation complex become very uh complex very quickly and usually lots of little details and back and forth are necessary with clients. So if you do this all up front, right, you try to scope out the entire project before closing the client, you're first of all going to spend a lot of time uh with meetings uh waiting for uh client feedback through emails. That can literally take weeks, multiple uh meetings. You're adding in lots of frictions. You have to wait for for clients to send emails back with with specific data points, etc. And in this process, lots of deals fall through, right? I've learned this the hard way and I've seen it happen around me too. Um, you don't want to spend so much time on on scoping out a project for a client not to convert at the end. Right? So, it's really important in my experience, the smaller the time window between the first call and uh the proposal sent, the higher the likelihood of conversion, right? So, of course, we do need the necessary information to judge the feasibility and to design a system, but we don't need all the details. We can do that during client fulfillment, right? So very important. So what are the necessary details? In my experience, it is first of all again defining the problem, right? Really important. A lot of times companies can't actually really define the problem that well at the beginning and you have to dig through a little bit. A lot of clients come for example with solutions. I need this uh but not attacking the problem and in the end they hire us to resolve business problems or business needs. Right? So it's really important for us to really understand the problem so we can design the best system to resolve that problem and the most efficient. For example, a client comes with, you know, I need a voice agent for inbound leads, but his actual problem is uh conversion rates, right? So that's in the end the problem we're trying to resolve. So maybe there's a better way. Maybe that's a voice agent, but maybe there's another way, right? I'm going to give you an example of of this uh in a second. Then second, we want to define the outcome. Now this is also really important which becomes a lot easier of course when we have defined the problem is like what should the outcome be now it's very important here again to get examples and specific requirements from the client on what the outcome should be first of all because we can use that to reverse engineer uh our system or our build right because in the end we have to work backwards from an end result and define what steps we have to take in the middle to get to that final outcome and second of all it aligns expectations Right? If if we get a specific outcome from a client, we know that if we can deliver a similar outcome that the client will probably be uh happy with it, right? So really important to get that that clear. Now clients again will not always have output examples. But even if they don't, let's say they ask for a personalized email system, it can be a good idea to ask them, look, write me one or two uh emails that are good personalized emails in your industry. And because then we can work backwards from those emails and also know that if we can produce an email like that, the client will most likely be uh be happy. Now sometimes of course a client will also uh rely on your domain expertise to actually write a good personalized uh email. But then you want to probably first define the outcome to the client. So you're aligning expectations. Then the third one that's really important is uh defining the triggers and the input data. So when should this automation, this specific automation or project run, right? And what data do we have access to, right? Really important to know what data we can work with to get to the final outcome, right? Then fourth of course we need to know which softwares need to be integrated into this system also again to uh judge feasibility. Do these softwares actually have APIs and second of all also to create an onboarding document for example where they can find the API keys etc. And lastly we also have to define uh the volume and the budget for this specific uh automation. how often uh is this this automation expected to run or should it run, right? And what's the budget of usage cost for this specific automation? Like let's say it's a it's a process that's not really solving a big need in a company and it's going to cost quite a lot in in usage costs. Well, then it's probably not a very good project for the business and it won't help their ROI, right? So, it's important to to define this in those first meetings too to again align expectations, right? So, get let me give you a quick example. So for context, this was a recent client of ours uh that had a coaching business and I think it's a good example because because of the uh scoping and and and planning phase, we actually ended up with a a different system than the client originally asked for. Um now basically how this co the problem of this coaching business was uh they ran a lot of LinkedIn uh ads uh and got in lots of leads through those ads. Um but their sales reps were overwhelmed with the amount of uh leads and basically their workflow was the qualified leads should be booked into a meeting and the unqualified ones should be sent to a lower ticket offer. Right now the big problem was as I as I mentioned here right the sales reps were overwhelmed with volume don't have enough time to manually review leads and set up meetings with qualified ones. Right? This of course resulted in uh slow follow-up times for the qualified ones meaning uh they left some money on the table there. uh it impacted the conversion rates and of course after that the topline revenue right now client suggested an AI voice agent to automatically call qualify leads uh to set up a meeting. I put here some uh example questions you can you can ask if you if you talk to a client to get to the the bottom of the problem, right? I'm going to make sure to share all the documents and the presentation of this this video um in the community if you're interested. So anyway, after finding the the problem, right, we tried to define the outcome. Now again I put in some some example questions here but the outcome of course for them the ideal outcome is qualified leads automatically were right away booked in uh for a meeting and the unqualified ones are uh sent a personalized email with a low ticket offer. Now I tried to ask for uh the qualification criteria which is obvious that we want to know what is a qualified lead and an unqualified lead. Uh and that's the funny thing they didn't have that defined well yet. So really important, I didn't wait for those qualification criteria before sending the proposal, right? I know I can figure that out once we get started, right? In the onboarding, give them some time, let their team talk, but first we're going to close the deal. And we know once we have that, we can implement that, right? Then uh for the triggers and the input data, uh pretty obvious here. Of course, the it should be triggered as soon as a lead uh filled out the lead LinkedIn lead form, right? And from that LinkedIn lead form, we got the following data points, which is the name, email, LinkedIn URL, and a company URL, which is optional, which is also important, by the way, to to know, right, if they're optional fields because if we count this in and we design a system based on we know we have uh the company URL, uh our system will break, right? So that's why these input fields have it well defined, what you always have available is very important because otherwise it's going to be difficult to design a system. Then for the softwares, right? And of course, we need the LinkedIn ads. Uh, go high level was their CRM and they already had a synth flow uh, account for the voice agent, but that was was optional. Uh, we could switch that for another one too, they said. Uh, and then lastly for the volume and budget. So, they had around 150 new leads per day. So, that would be the amount of times this automation would run. And for the budget of this automation, the alternative was to hire more sales reps to be able to handle all of these leads. And so budget really won't be an issue for this one because I know this automation is not going to cost uh more than one or two employees. So if you're new to this uh I can imagine the hard thing is in the beginning understanding what pro projects are actually feasible and what not right and I think the intuitive thing for people who are new to this and maybe have their first client or their first two three clients is they want to scope out everything right to make sure that it's actually possible that they can actually do it uh before closing the client but again right I highly recommend to keep the time window between the first call and proposal and uh client paying as short as possible even though you might not know what you're doing yet, right? So why is that? Because first of all, you have to show trust and confidence to these clients, right? Uh and you can only do that when you actually can talk confident with them. Second of all, most of the time you will figure it out during the process. And thirdly, in the worst case scenario, you wire them back their money and you've you've learned a lot, right? because during these client projects you actually learn the most right this is at least the approach I took with the first four to five clients I didn't really know what I was doing but I just jumped in show confidence tried and I was able to figure out figure out all of the the projects during during the project and it's also where I learned the most right so highly recommend you take a little bit of risk it's not risk in the end right uh but just jump in and and try it because that's where you're really going to learn which brings us to the second point the system design which I've broken down into four u steps right first we want to as I said before we want to reverse engineer right and think backwards from the outcome right what do we need to do to get to the outcome so we already know we need this company needs qualified leads need to be booked in uh as quickly as possible and unqualified leads need to be followed up with ideally with a personalized email sequence or something um to uh to the low ticket offer right now in order to get there of course we first need to know what is a qualified lead, right? So, we need lead qualification or lead scoring system. And in order to qualify or score leads, we actually need data on those leads, right? So, we need to research leads, right? Which brings me to the second point, which is break it up, right? This is really important. Uh I think also when you're starting, break these larger projects or any project really up into smaller uh parts or phases, how we call them or sub projects, right? And basically the way you want to think about it is like what's the shortest path to deliver value or a win to the client. Now why why do you want to do this? Because first of all most we're still in the early adopter phase right most companies are extremely skeptical still with automation services with AI in general etc. The quicker we can show value and we can show that these systems actually work to the client the more likely they will stick with us. Right? that first of all and second of all we don't want to scope out the entire large project just yet again because we might need more details to actually do that. Um and second of all we over complicate right we want to if you come from the startup world you want to have an MVP approach what's the minimum viable product that delivers value to the company right and build on top of that right iterate improve and add on top of it right so if we look at this project I would break it up into three three phases or three sub projects which is first the lead research second lead qualification and third uh the actual voice agent or email sequences right now. Why? Because the lead research most likely will already have lots of value to the company, right? Because if I can find relevant data points for the sales reps, put them in their CRM, they'll probably already save a lot of time uh when when researching leads or they can quick quickly tell which leads are qualified uh and and which ones not. Is it an ideal system? Not no. But it is better than their current system. So, and second of all, they'll probably be better prepared for the meetings. So that would be my first phase, right? Second phase would be lead qualification and the third one that I would add another point. If you have a client that wants multiple or lots of automations, which happens too, right? They have lots of ideas in in mind, start with the one that's the quickest and easiest to deliver with high leverage for the company, right? That really delivers a lot of value to the company. In general, I won't re I wouldn't recommend running multiple automations in parallel at the same time because again, right, MVP approach, we need to show something, iterate, improve. Rarely is it perfect on the first try and if you're going to run three or four automations at the same time, it's going to be very chaotic. So, in general, I recommend going one one by one and focus on the highest leverage uh ones first. Of course, some companies that need to do a lot and have a big budget, you could you can start doing this. But I think the best when you're when you're starting out is just to go one by one. Now, the best way to design the system is to quickly use uh a diagramming software, right? Even if it takes you 10 15 minutes, it's going to really help you save time in the long term. Uh because you already understand dependencies and things like that through diagramming. So, I use Fig Jam which is uh free. It's from Figma. uh but some people use whimsical draw.io I think it's also free uh or lucid chart and I highly recommend you do this especially if you get started. So let me show you a quick example of how how I would do this uh for this project for example. So again I've already broken it down in my head into three phases. So I'm not going to work backwards all the way from the voice agent etc. I'm going to first focus on phase one which is the lead research right and and we know the outcome right because we already have uh that information in our scoping right so the outcome ideally is uh an enriched enriched CRM or enriched lead right in the CRM right that would be the outcome now what data points do we need in that outcome we got that from the scoping call. All right. So, these are relevant data points for the sales reps. So, we can just add them here. So, we know what we need to get to. And we also know that the trigger is LinkedIn ads. So, we can add in the trigger. I can give it a different color so we know it's a trigger. And we know the input data or the input fields. LinkedIn ads are the name, right? Email, the LinkedIn URL, and the company URL. But that one was optional, right? So now we know this is the information we have and this is the outcome, the ideal outcome, right? So what's the shortest path from A to B? All right, that's all we have to define right now. Now, if you're completely new to this, uh it's going to take you a bit more time and figuring out if what's possible and what not. If you have more experience, this will be a lot more a lot easier. And eventually, for these simple ones, you don't even need to because you've already done them a few times. So, you know, you know how to resolve this, but it's still good to to to plan this out. So, I already know these three data points, right? Lead summary, the current job title, and the years of experience. We can get easily with the LinkedIn scraper, right? which you can do with uh ampify right which is you can use in any of the noode automation software right so we can use LinkedIn scraper and we basically can cover these three data points already the company size and the company summary we don't really get from uh the LinkedIn scraper because of course we're scraping the personal LinkedIn right so there's we can for example uh if the company URL is available right which is a dependency or which is logic condition. Uh then we can scrape the website for example, right? Scrape website where where we can at least get the company overview. Company size not necessarily. So if company URL is available, right? Then we I already know that if you scrape this LinkedIn personal LinkedIn profile, you sometimes also get the company LinkedIn URL uh from the company they currently work for. Now, it's because I already know that's why this is not uh always possible to to perfectly uh define at the beginning, right? When you're building, you're going to add some things and you're going to see some new things, but it's still good to get that initial idea, right? So for example uh we can say here scrape company LinkedIn URL but only if only if uh if company LinkedIn URL is available. Now we know this. Now if both are not available we have to go directly here. Right? And maybe in this case we don't have the company size yet. So we can add in another condition. All right. Basically add in that same one and also scrape this one. Right? So if the company LinkedIn URL is available, we'll also scrape we'll scrape both the website and the company LinkedIn URL and then we get all the data points. Right? Now, of course, we need to uh add in a language model first, right? To extract all of this data, right? So, LNM, right? And this extract data points.

**[147:05]** All right. Now there is a possibility we don't have access to any of this right but we know at least for this route and for this route we have all the data points. Now of course it can also be this route in this route we miss the company size right and in this route we miss the company overview and company summary. Right? So that's why I put this asterisk there because we won't always have access to this in the future. Right now, of course, what we can do is add in lots more scrapers, Google search scraper, etc. to try and do everything we can to try and find this, right? But again, we're designing an MVP first, right? This is already going to help this company a lot more than what they currently have, which is nothing, right? Or they have to manually look it up, right? So, we're first going to start with this and we can always add on top of it. And it's important to note this because now we also know that if we're going to then add in lead qualification later, we we can also tell the company that these are the data points we can work with and these are not always available. Right now, I'm thinking about it already. If this is not available, he can probably say it's an unqualified lead because it doesn't currently work for someone. But again, you can let them decide that. So this I would define as phase one, right? And I already know this is quite easy to do, right? So this would won't take me longer than a week or two, right? And we can show a clear win to them in a week or two, right? And from there, of course, you can uh you can add on top of this, right? So we can go with the let's say we keep this in in phase one, right? Then we can go with the lead qualification, right? And here we already know we need some we need some data from them, right? It's like what is a qualified lead, right? So this is a dependency which we put into the the proposal,

**[149:09]** right? And again that needs to be updated. All right. And that would probably be phase two. Again, that could probably be done in a week. But again, usually these systems need uh once they're deployed. Uh people use them a bit. They'll see, oh, uh Ben, can can't you add another data point, right? So, we have to actually adjust this. That's usually in the real world how it goes, right? Can we add in another this? And then we find another scraper we can add so we can get another data point, things like that. Instead of designing this whole email sequence already for for unqualified leads, we are still at the beginning of this automation, right? And this could I could deliver it in a week but they could ask for optimizations and it could take another one or two weeks right so we don't want to spend too much time on scoping out all the the work at the back right so lead lead qualification updated CRM with the lead score right that would be phase two

**[150:11]** and like that we continue right and of course like from here we would So you know let's say the voice agent right and uh email sequence. Now again here there are going to be lots of dependencies again right it's like what happens if someone doesn't answer the voice agent uh where does it need to update in which calendar uh what happens uh do we have to send them to an email sequence if they don't answer what happens if they're not interested things like that so we don't want to go through all the details we already know this is going to be a little bit of a bigger project so we can sort of give it a timeline so I'd give this one to two weeks one to two weeks and this probably a bit longer uh but that's what we then can put in the proposal, right? And I can already tell you, we delivered this to the client uh after a week or two, they loved it and it already helped their sales process so much by just having these data points available in their CRM. Then we added this part which actually took quite a while for them to figure out their own lead qualification system and I helped them out with them with it a bit. And after that uh they actually decided they don't even need the voice agent because this lead qualification system worked so well that they could just filter by the top leads. That reduced down the amount of leads for the for the sales reps so much that we could easily handle uh the amount of leads and we ended up only adding the the email sequence for the unqualified leads, right? But it just shows you that you know breaking it up uh into interphases is really important, right? and also to show quick wins because again these guys had no idea what's pos was possible with AI they were a bit skeptical after only seeing this which is really basic right they they were blown away right but this just magically appearing in their head into their CRM uh they they they were they were amazed that's that's how easy it is a lot of the times so that's it from there we basically once we have an idea of this and of course you get faster at this and after a while especially for the simpler ones you don't have to map it out completely you already have it in your head But uh from there we we send the proposal, right? And I'm going to show you a quick example too. So then you can add those phases into the proposal, right? And usually we add an onboarding dock or we do it in the onboarding call, right? Where we actually set up um the integrations with the software, right? So let me show you a quick example. So this is an unrelated proposal, right? But just so you get an idea. So we have the breakdown of the phases, right? Then we have phase one with an estimated uh time frame per phase, right? Now in this case it was an even larger project so we broke uh phases up into subphases even right but you get the idea and then we have the subfase for example in this case lead research and update CRM right the action what are we going to do right and the output what can they expect right what's the end result of this first phase and the dependency now in this case none but let's say in that second phase dependency can be we need to have the lead research but also we need to have the lead qualification criteria right and For the third one, we need um an example of a personalized email, etc. Right now, that's that's sort of how we lay it out then. And now, for prices, we do uh always do subscription based pricing. Uh it works by far the best in our experience because again, uh most of the time when you deliver, let's say this first phase, uh in this case, for example, the client loved it, but they wanted some extra data points. Um which is perfectly fine, right? We want to add and improve on the system. But if we've already quoted them for a specific project like that and they want to add things on top, we have to quote them again. We're adding friction to the process. So because they're on a subscription model, they have a lot there's a lot less friction. We can improve ad on existing uh projects and they will understand too that the exact timelines won't be complied with if they want to add something to uh the the the first automation etc. So it becomes a a lot more flexible and and a better relationship in my experience if it's subs subscription based pricing because if you do this project based you either have to scope out all the needs and the entire project uh completely which is going to take you lots of time right and if they then want to add something on top or or something doesn't work then you would have to add another quote on top of that and again it just adds friction. So high you recommend the subscription model and that's it. Uh and then we do the onboarding call where we uh explain how to to integrate the softwares right we always set it up in their accounts and uh that's it. And then the next phase of course is we're actually building it. Now I'm not going to show you the actual building. I have many videos on my YouTube channel if you're interested in learning how to build. But I'll show you quickly the steps we take when we are developing these these systems. First we build and test step by step, right? So we make sure that every node or module or step works before adding the next one. Uh now again you you can predict sort of the edge cases and where it can go wrong. But also don't overoptimize, right? Again have the MVP, minimum viable product mindset in mind when developing this, right? If the automation fails maybe uh on two over 100 uh uh leads, right? Because the LinkedIn can't be scraped, etc. It's fine, right? It's still going to add a lot of value uh to to the company and it's a win for the company, right? Because before this, they had nothing, right? So, we can add two or three more weeks or whatever onto the automation by getting it perfect. But if we can get uh it a 90 or 95% solution uh in a lot shorter time frame, we should aim for that, right? Of course, there are are exceptions where there are really important tasks that can absolutely nothing can go wrong, right? That's a different scenario. But in general, right, aim for the MVP uh approach, right? Then and then iterate and improve of course uh uh on the system once it's in production and and being used in the real world, right? And once you get feedback from the client, which is really important for you to be able to improve the system, right? Then once you've built the the entire phase or the the system, then you are going to test it on uh ideally 10 to 100 examples, right? you'll need usually you need to do some debugging there and improve the system there already. Uh then we usually add in error handlers, right? Um we always add in these retry mechanisms for API modules, especially if you have large um volume automations. APIs fail. It's it's very common, right? Uh because we're relying on their servers and and things go wrong. Then lastly, uh we we deploy, of course, and and that's where it sometimes just starts, right? after getting feedback, after the company trying it out, um you usually they get lots of ideas on how to improve the system, how to add things to the system, uh how to iterate on the system, etc. So, you'll have a cycle here of improvement, right? And adding things and of course, if everything's running really smoothly, we can continue uh with the next automation or the next phase in this case and expand on the current automation. Now, I highly recommend uh when you're working with clients to open up a a Slack channel with them or invite them into your Slack channel to have a direct line because this this is really required with these automations. You're really working inside of their business. So, it's really important uh you're in line, you understand you constantly need uh some things from from them, etc. So, of course, you don't want to overdo it, right? You don't want to be spamming them. Uh you want to be professional, right? uh we we usually try to limit our our our requests to once a week but uh in general it's good to have sort of this open line and for us Slack has been uh working the best. So that's it. I hope this uh this helped some of you. Uh I know it was very client focused but I think if you're just building your first automations, this also gives you a good idea of how to plan out your first automations yourself and uh maybe how to eventually uh sell this to clients too. So now that you know how to plan and scope AI automation projects, it's of course very important to get some practice in and start building some automations for yourself or for your company or for some friends. That will really solidify what you've learned. But we can also take it now to the next level to the part which I think is most interesting, which is learning how to build AI products. AI products will allow you basically to take your NAN and automation skills and package it into a system that can be resold to tens or even hundreds of businesses without customization. This is of course the approach we took uh with our AI SEO product which we've now sold to more than 100 businesses and grew to $1 million in ARR in less than a year. Now, first we're going to talk about how to design these kinds of AI products, which tools to use, and I'll show you a quick example of our AI SEO product. Then we're going to build an entire resellable AI product entirely from scratch. Now, the next part can be a bit more advanced and you might not fully understand each concept completely yet. But don't worry, that's completely normal and it will make a lot more sense when we actually start building one of these AI products uh from scratch later in the video. So, I'll first cover the core infrastructure for AI products, then the tools I recommend using when building them, and then um I'll cover how to design AI products the right way. Now, the core infrastructure is no different than traditional software, right? We have a back end, we have a database, and a front end. Now the big difference is in the back end of course we're using lots more AI and AI workflows. Now one mistake or one I think pitfall many people fall into especially non-coders is now that we have these tools like claw code and lovable etc is they decide to build out the entire product through code right away. Of course through these coding agents it becomes a lot easier for us to build this. But I still especially if you're a non-coder highly recommend to stick with no code when you're just starting and building your your first prototypes and your first your first systems. Why? because you do slow down the product iteration loop, right? You want to keep that as agile and fast as possible because if you want to make a change, which you're constantly going to have to do when you're just building out your product and and and having your first customers, even with the coding agents, making adjustments to the back end, database, and front end is going to take quite some time. And you can also not check the code if you're not a coder. So, it's going to be hard to know if it's actually production ready, uh, to know where the errors are, etc. So highly highly recommend sticking to no code when you're just building it out especially now that we have platforms like Naden which are very solid infrastructures for for building sort of your MVP back end uh for these AI products. The second uh mistake I see many people making mostly in the in the AI space or maybe doing the AI automation agency many completely ignore the fact of front ends. So a lot of these AI automation systems are being delivered in databases or raw spreadsheets. Uh now I highly recommend you get used to uh building some front ends right because front ends are really what the client and the customer is going to use uh with your automation system. So if you have a simple front end a decent front end the perceived value of your system or your your AI system really goes up 10x instantly because it really feels like they're getting a little bit of a product and secondly will really help you if you potentially want to productize you getting in the habit of building front ends for your systems is really going to help you uh potentially productize. So what is the tool stack that I recommend you you start out with when building an I product? It's uh the one we use for our AI SEO product which is the back end in NAN uh the database in Air Table and a front end in Air Table interfaces. Now the huge upside of this setup uh in my opinion is that this has the fastest product uh iteration loop right and you really want to keep that flexibility when you're building your system out right so because you can basically build an automation system in NN in a couple of hours you can set up a database in air table in a couple of minutes and build a front end on top of that in the same software in literally minutes too. So you keep that product iteration loop really really fast. While if you use a software maybe like Lovable and you build out your front end and custom code with a database and Superbase etc. Every iteration or change you're going to make is going to take you a lot longer than if you use this setup. So I highly recommend this setup in the initial stages. And you might say okay this is a great setup maybe for your uh prototype or your first MVP. But we've actually scaled our business to over $500,000 in revenue with still having this setup right. So you can actually scale this. Now the business model we use is we actually sell the entire package or the product and uh install it onto their computer. So we sell it at a high oneoff fee price basically sort of like the old software days. Uh now of course if you want to build this into a more recurring sort of SAS type business model this will probably not be the right setup because you can't really use an air tableable interface as a SAS right you can't integrate payments etc. And there are some limitations to using N as a SAS and and a database. But if you if you're building out your product, I think this is a great setup. And we are not the only one using this setup. Uh Stephan Pope, a fellow YouTube creator, also created an AI content system with the same setup. Um and there are some other examples. I can show you very quickly our AI SEO system. So you can see uh this is our our dashboard, our Air Table front end. And as you can see, it doesn't look uh probably you can build something nicer in something like Lovable, but it's very much 8020. I think it looks very good. Um, and you can make these iterations really really fast. I'm going to walk you through the SEO system in more details in a second when I talk about how to design good AI products. Uh, but just to give you an idea of the the front end you can build. I see here we have the N8 back end, right? It's quite big right now. But we've built this up and iterated a lot over the last couple of months and we basically started out with something which is probably like 25% of this. So that's the huge advantage of having N as a back end. you can add on top and iterate on your back end really fast and and quickly. Another example I just saw on uh on this one is from uh some guys here who build a a content system here on Air Table. You can see looks pretty good too. But uh there's multiple people using this setup uh to sell AI products. Now if the downside of course of this setup is that first of all you can't really make this into a SAS right because you have it in air table interfaces. Uh so if you want to go the SAS route, I'm going to give you some other recommendations of tools to use. Uh second, because we are selling the actual product onto the computer of our customer, we don't have access to their performance data, which of course is a big thing you're missing when you're using this business model, but it could still be good in the initial stages because you really get good cash flow if you use this business model we are using, right? And eventually maybe transitioning to a SAS, right? And the the other downside is if you use air table as a database uh you do have some limitations with the amount of records you can store etc. So if you really want to go the SAS route I'd say in the MVP stage uh you you you probably cannot use air tableable. So you want to explore uh some of these tools right? So no loco code glide softer retool and crossi are basically no code tools to build front ends uh a little bit quicker than with traditional code maybe h and you still have more flex flexibility and customization than a tool like air table interfaces. Now some of these tools also have built-in databases that are a bit more scalable than uh air table or google sheets etc. Um but these generally also have native integrations with popular databases like Superbase, Air Table. So you can link them directly to your existing databases or you can uh build a database directly into these softwares. Now the advantage of these softwares is you can uh basically integrate Stripe uh login uh really fast and easily. So if you want to go the SAS route and you want to start MVP and have that fast product iteration loop, I highly recommend checking out these tools. Retool and Glide are generally more focused on inter internal app building. Uh I I like no loco and softer if you want to keep it flexible and lean and cross is one that goes mobile first, right? So if your your app or your your product is going to be mobile first, then it's worth exploring this one. And of course you can use other databases too, right? You're not limited to these. So how do you build a good AI product? Now first of all to start with how do you build a product that does not compete with JPT? If you're building AI products, you're almost automatically going to be uh uh compared to chat GPT. So, it's really important that your tool offers more value than chat GPT. And a good way to think about this is what are some of the limitations of CHPT because there definitely are some downsides to it still, right? So, the first ones are of course L&Ms are generally still not perfect, right? They are unpredictable. Uh there are some hallucinations. Uh so, the way we go around that is by building lots of human in the loop in the system, which I'll get to uh later in this section too. Then uh the second thing is typing can actually be a really inefficient way uh to to execute on a process. You just think of yourself how many times you had to reexlain the same thing you're trying to do in chat GPT over and over again uh to to to chatpt. So we can actually build an interface that is much easier to use uh uh for a specific process right which I'm going to get to in a second too. Then uh we also have a problem of having limited uh context inside of uh chatpt both on the process the specific process you're trying to execute. So let's say again we take our SEO uh as an example. Chat GPT might not know exactly what the best way uh to do SEO is, right? It might not have all the context around what the best process is around doing SEO or uh the context on how to do SEO for your company, right? And the second uh big downside there is also has limited user context, right? Think of how many times you had to explain chat about your personal situation, about your business, about the exact process you're trying to do. So, we want to integrate that into our system, right? and have that integrated proven process that domain expertise on how this uh workflow should be executed integrated into our system. And lastly, we don't have continuous learning in these systems. So that's something we can really start building into our um AI products, right? Is where we capturing decision-m data uh and performance data which slowly but surely creates a mode around our product uh where we really have more data to execute on this specific workflow than CH GPT. So, I'll go over each of these uh in more detail. So, the first thing you want to keep in mind, and uh Andre Karpathi talked about this in his last talk uh software 3.0. I highly recommend checking out that video. He explains it a lot better than me probably. But the key here to keep in mind is the way we want to design AI products at the moment is by having lots of human in the loop, right? And he he shows it basically with an autonomy slider, right? We want to start out very much on the left side. We want to keep a lot of human involvement uh in the beginning phases and slowly but surely we can have more autonomous systems but we really want to start out here when we're uh just building our first products right and way we designed this is by having lots of human in the loop and basically the way you can see it is we have the human as the verifier and the AI as the generator right so human manager right AI executioner that's really how we can see these AI products and the faster you can get this loop the more value you can provide to your customer so we really want to keep this loop loop as fast as possible. And and the way to speed this up, for example, in comparison to chat GPT is by having less typing to do, having uh better sort of internal prompting into your system where the AI generation is better. But we really want to try to keep this loop as fast as possible. And the big upside of having lots of human in the loop in these AI products is first of all, and this is something we've learned too uh while building our our AICO product is most people still want to be in control. They don't want to have a perfectly automated because first of all we cannot perfectly automate things but people still want to be in control of making decisions right especially important decisions. So they don't want a system that automatically uh finds ideas uh creates blog posts posts them on their website etc without ever checking or verifying what's actually being done. And the second big problem we solve here is the edge case problem. If you've been building uh automation solutions you know you can probably spin up an automation uh workflow quite quick. The hardest thing is actually uh building the solution or the infrastructure around edge cases which you will always have right because optimizing these systems for edge cases is actually where you're going to spend the bulk of your time. So this human in the loop sort of setup really gets around that edge case problem because the human is still the verifier. So you don't have to design a per overgineer perfect system that resolves all of the edge cases. The human can just sort of spot them and uh decide to not go ahead with the edge cases. Right. The second the third thing it it really avoids it avoids the the enm problems we still have rights can still be unpredictable. they can produce hallucinations. They they don't they're not perfect yet, right? And because we have the human verification and lots of human in the loop, the human can go go around uh the the problems of L&M at the moment. And lastly, this gives you this sort of setup gives you a lot of data on how your users use the system, how they make decisions, which eventually you can add into your system to really make it more autonomous, right? And slowly but surely, once you have more performance data and user decision-making data, you can make it more autonomous, which I'll get to in a second. So the way you want to build this out is not by building an enormous workflow, right, that automates the entire process, right? We've all seen it, right? The 100 node N workflows or 20 AI agent team, me including, right? It's really exciting to build these systems, but it's a blueprint for disaster, right? N&M are not perfect yet. We're unpredictable and these sort of setups just become really, really errorprone and not production ready, especially for AI products. So the way we want to approach this and I highly recommend taking this approach even if you're building custom solutions for clients but especially when you're building products is to really build as granular as possible and have as much human in the loop as possible. So the way you can look at this is understand the process, break the process down into the smallest tasks and then build a separate automation for each one and then you can bundle them into a product right and this is also the way you can start very lean and with a small prototype by just having let's say two or one automation task and then you can easily add on top of this right without affecting each all of the the previous automation workflows you've built right so if you take a content system right think of a content process is not just uh writing a post right away, right? There's actually lots of smaller steps in between. So, we want to first go with idea generation, then with maybe angle generation, right? Give a few options to the user, let them choose, then a few options of writing the posts, let the user choose, then a few option of images, let the user choose and iterate, right? So, we really want to build granular. Don't try to automate that entire workflow in one go. Right? That will make it a lot easier for you to build these AI products. So the way we do that is by basically having sort of this one web hook in uh that connects to our database and then we have a switch node here that basically connects all of these smaller workflows in the smaller automation tasks inside of the larger workflow. So instead of trying to automate the entire content creation process in SEO in one go which would be extremely errorprone we break up the entire workflow of doing SEO into very granular steps and tasks and in each of these tasks a human verifies the output takes the decision makes the iteration if necessary and uh executes on the ne next task in the workflow right so really try to break it down and the huge upsides of this is first of all you will have less errors you have way faster faster iterations when you're building this because if something goes wrong in one specific auto uh uh part of the automation, you can just go in there, resolve it without affecting it the entire rest of the automation solution. You can easily add features uh uh on top of your existing system. You'll have more data, right? You're you can log uh the user decision-m data. Uh you have better user experience because humans are more in control and you'll have less errors. And you can also make this system eventually self-improving which I'll get to in a second. So the way we generally set these systems up and I can show you quickly in the Nad here it since my picture there we already have expanded it as you can see and of course you don't have to start out here right we started with 25% or 20% of this entire workflow and through feedback and product updates we've slowly but surely expanded the system into this and now it really takes care of the entire SEO uh sort of sort of process. But the first step in this automation is sort of that context generation. Again, these systems you don't want to design as a one-sizefits-all. We do want to give the system context on the business, right? SEO requires context on a business to drive to write good content. It needs a strategy for the specific business, right? So, this is generally what we do. And this is not only for SEO, this is the same for content, right? If you're producing content, you need the system to have context around your business, about the strategy, about the target audience they're trying to reach. So the way we designed this is by having these sort of first workflows is always the context generation for this specific client. So these part of the automation is just doing that and I'll show you how that works in in the the front end. So I'll open the air table here. So basically here in this SEO project setup, what we have is company information. So here a company could put in their information their name and their URL and instead of us uh telling them hey write out your strategy and your business overview uh etc yourself we try to make it lots easier for the user. So we generate an initial draft of the strategy and their business overview through scraping and AI and from there the user can make adjustments etc. But the important thing is we have that context here. Now you see the system automatically generates this business overview and SEO strategy. The user can still adapt this but this will then feed into all the subsequent workflows to give the system context on this specific business which is really going to improve the output right combined of course with our domain expertise around SEO and how to actually write good articles etc. But this is really a key ingredient for these AI products, right? It doesn't mean it's a one-sizefits-all. It needs the context on each specific business. But make it as easy as possible for the user. And the same here we have, for example, each company might have a different CMS, right? But again, we make it easy for them, right? They can just choose their CMS. They can put in their API keys even and our system will automatically then uh connect that, right? So uh this this is sort of the setup we use in that first step. uh let me go back to the presentation and then from from there you can really start automating the the workflow right task by task. So you have for example idea generation first you generate 30 40 ideas then the human chooses verifies and chooses the one they want to go ahead with right again you go in the next stage our SEO system by the way is far more has is far more granular than what I'm saying right now but I just want to keep it easy then this the third step might be drafting the blog post again you let the human verify before taking the next action which is adding in the images or doing the keyword research right human verifies And what we're uh testing right now too and what we've just built in to our system is even having performance analytics. So um basically the our system checks now uh for how these blog posts have been performing checks which ones have been performing best makes a report on it and that perform that report we can then use as context generation again when we execute the workflow again and that's how we can sort of start building a self-improving system too. So I think this part is really interesting to to focus on any solution you build. If you can have some performance analytics in there, you can really start building self-improving uh products. Anyway, if you want to learn more about how our SEO product exactly set up, I do have a full tutorial on our on our SEO system too. It's a little bit outdated, but I think it will give you a good idea. So that's it for the back end, right? Keep it really granular. Again, you don't have to start out with a huge workflow. Start out with one or two of these, right? And you can build from there. And that's really how you build the prototype too. Now for the database again, right, you want to keep it really easy and fast to iterate and adapt because any change you're going to make there in your N9 workflow, you your database is going to be affected. That's why I'm such a big fan of starting with with databases like air table because you're really flexible. You can make changes really fast. So uh because the database really the core of your your product, right? And therefore fast iteration is key, right? I can show you very quickly how this looks in the back end. So you can see this is the database where the front end is built on top of right and you can see it's quite quite straightforward and then we separate it through tables for each of the parts of the processes of doing SEO right bottom funnel middle of the funnel top of funnel content here we have tech audit here we can set up all the pro all the different companies you want to do SEO for etc again if you want to learn more about how to set up this this entire infrastructure and how to build an MVP I do have a full uh uh tutorial on how to build it from scratch so that's it for the database now for front end. Again, same here, right? You want to have a front end that's easy and fast to iterate than that because again, any change you're going to make in the back end and in the database will have to be reflected in your front end. And if you have some solution, custom code, it's going to take you a lot longer. That's why I'm such a fan of the combination of air table and air table interfaces. Second, you want to have lots of human in the loop. This is really one of the biggest lessons and what Andre Capathi says too, right, is human in the loop is the way you want to design these AI products at the moment and to go around the issues of AI that we still have. And lastly to really have a better user experience than chatpt you should not focus you should design your user interface as much as possible around just clicking right just choosing and clicking instead of writing data entry chatting etc right and that that's how you make the user experience a lot better by having a proven system uh and by having an easy and fast to use user interface you get better results and faster results than with chachpp And that's really how we can stand out and and make our product differentiate from ChachiP right so again if I show an so if I can show you example quickly if I go back to the air table so the way we do it here is in air table with just quick actions right here for example generates ideas for blog posts with a little bit of a description I choose which one I want to go ahead with if I have decided to go ahead on uh specific one I just click here on generate content right the generated content will be presented here again I can analyze the generated content. Normally, I can then decide to actually publish it, but again, I have the human in the loop. I can verify everything, right? I can verify the images, right? I can make changes if I want to, but if I don't, I just click a button and it will be published, right? I can even schedule the date, etc. So, you want to keep it as fast and easy as possible for the user. Uh, instead of them typing, yes, you can now publish, etc. And I I see that happening a lot now that we have agents, people are designing a lot of these systems where where you have to talk. But if you're automating or or really resolving a specific workflow, it should be really easy for the user with clicks to go through that workflow instead of chatting. So hopefully by now you understand a bit better how to design these AI products and which tools to use. Now don't worry if you didn't understand everything yet because now we're going to build one entirely from scratch. You're going to learn how to build uh these front ends on Air Table and user interfaces, how to set up databases, and how to plan these AI products. So, let's dive in. So, I'll first show you a quick demo. I've just built the entire system from scratch, which you'll see me do in a second. So, this is basically the last part of my recording, but I just wanted to put it in front to first show you a quick demo. Now, uh here we have our LinkedIn agency in a box. And the whole idea behind this system is that you can manage the LinkedIn content generation for multiple businesses inside of this same system. And of course, this is an productized AI system, meaning you can potentially resell this same system to multiple businesses without any customization, right? So, of course, I built this entire system for in one and a half or two hours, I think. Uh, so it's far from perfect yet. Building really valuable AI productized systems usually take a little bit longer, but I think it will give you a good idea of the infrastructure we use to build these productized systems. Uh, and you can build on top of this quite easily. So, it's just to give you that's really the purpose of this video to teach you how to sort of approach building these productized AI systems. So, we basically have four different sections here inside of this system. First, we can set up the campaigns for the specific company so we can manage the multiple companies. Of course, we want the system to personalize the LinkedIn content based on each company, which we're going to do in this step. Then, we can uh check the analytics for posts we've done, but also for past posts. And we can reference specific posts we want to use inside of the system when generating new ones. For example, to mimic sort of the tone of voice or style when generating the new posts. Then we here we can request uh new LinkedIn post and gener the generated ones will be posted here in this section too. And then we also have a built-in content calendar. So let me just show you a quick demo. So here if I go to the campaign setup here, I can manage the different companies I want to do uh LinkedIn content for. And you can see we have three ones set up here. Uh this is just dummy data. Uh but this is my company here. And we can add new companies here too if we want. And here basically the user has to provide some information uh to the system on this company. And from there we're going to personalize it uh for each company. So first we have the company info which of course the company name uh the company URL and the company LinkedIn URL. Then we have uh the LinkedIn post references or for or for analytics. Right. So we have the user LinkedIn. In this case, I just use my personal LinkedIn. And then we have two reference LinkedIn URLs which we can use basically if we like some other creators who uh have a specific tone of voice or style of writing. We can add them in here to sort of use those posts as references when generating new ones. And then we have an action here which is generating the information. And I'll show you how this works in the back end. So I click here on test workflow and I go to uh click the action. You'll see what happens here in the back end. It the AI agent here together with perplexity will basically first do some research on this company to generate a business overview the ICP for this business and a value the value proposition for this business. Now why are we doing this? Because it's important when we're generating these new LinkedIn posts that uh the L&M has context on what this business does and who their target audience is. Right? So that's why we're generating this here. And then of course here in this node we're also scraping all the reference posts which we can then select in order to sort of mimic that tone of voice and style of those creators and of course it will update it back into the air table. So if we go back now to the air table now you can see we get a business overview right we get a value proposition and the ICP right so Beni agency provides advanced artificial intelligence solutions designed to empower businesses across various sectors by automating personalizing and optimizing their operations uh etc. So long long text here uh but you can see it's quite in-depth and this of course we're going to use when we're generating new post and the key thing here is we still have human in the loop right so someone can still change this maybe add some things iterate on on it etc we have the value proposition 2 and the ICP uh so we can do the same here for HubSpot just so we have it

**[184:57]** so we'll do the same for Hopspot and in the meantime time we'll start going to the next section. You can see now it also scraped uh these different creators with the LinkedIn post of these creators with the amount of likes. So, it's automatically sorted uh based on the likes, right? And we can see the the post in detail here. We can we can select sort of the tone of voice uh of the type of post that we like. Now, I'll just use mine. So, let's say we're going to use this one. We can just check mark it here. Right? This is also mine to sort of mimate my tone of voice. So let's select these these for now. Uh now we can go back see what if Hopspot's already updated. Yes, we got the same thing for Hopspot. And now we should also have the reference post for Hopspot. Yes. So we can select some here too. And now we can this these selected ones will be taken into account when we're generating new ones, right? to mimic that that sound tone of voice. So just put a few examples here. So here I can request a new post and when I request a new post I can decide for which company. So in this case I'll do mine and then the way I've set up this system is to basically repurpose use um YouTube links or blog links to uh use as context and then it can repurpose from that context into a LinkedIn post. Now if I had had more time to build out this system, I'd probably put some more input types here. Maybe just a short prompt uh to to for user to tell what kind of post it wants to generate or maybe different types of inputs like podcast. You could think of some others. Uh but I didn't want to make this an A hour tutorial. So I'll just take one of my last videos, right? AICRM. Uh I'll put it in here. And then I select YouTube. And then I can also decide which type of CTA I want to use. So let's do comment. And then I can also add in custom instructions uh for the post generation and also custom instructions for the image generation. I'll leave it empty for now. Now let me show you what's going to happen in the back end. So if I click on test workflow and I create this, you'll see now that it first starts scraping the YouTube transcript. Uh right, then it takes all the information about the company that we uh generated earlier about the ICP etc. and the referenced LinkedIn post and passes all of the information together with the YouTube transcript into this L&M chain who will generate three different types of uh uh LinkedIn posts uh with three different frameworks basically a story based one an insight based one and sort of an engagement type post now ideally if I would have more time I'd probably give the user the option of what kind of you know posting framework you would want to use but again I didn't want to make this too long here generate generated the prompt for the image generation according to each of the the posts. And now it's using the OpenAI image generator API to generate three different images. Now, this going to take a while, so I'll speed it up quickly. And now it's updating the air table. So, if I go back, you can see we now got three uh new post. So, let's see. So you can see it pretty much took my tone of voice definitely and my style of writing if you know it. I usually use these exact emojis right and also with these. So it definitely copied my tone of voice. How we automated our entire sales process using air table and cloud manual sales admin is a silent productivity killer. Here's how you can bring fully automated CRM in air table. Zero touch lead research and qualification real-time meeting analysis. So pretty good. So this is an insight focused post and we also have uh this one is a storybased post. A few years ago I found myself buried under a mountain of sales admin work. If you've ever been responsible for sales finance or regulated industry, you know what I mean. Time spent researching lead endless meeting prep etc. Something had to change. That's when we decided to build an end toend sales automation system. So pretty good. The whole point is we have the human in the loop here, right? So, we can still adjust things before actually deciding to go ahead with it. And let's see the image. Pretty good. I'd say we could probably improve this inside of the system, too, to make it more sort of brand aligned. Give it some examples, things like this. But it's not bad. We can check the last one, short shorter one. How many hours does your team? Yeah, pretty good. Uh and then let's say we like a specific post and we want to add it to the content calendar. We can just uh click here on schedule post. We can select the date we want to post it on. So let's say for Saturday, right? And now automatically this post will be on our content calendar here. You can see on Saturday we now have our post here. And of course I didn't set this up for this specific one, but we can also automatically trigger an automation to actually post this on LinkedIn. uh directly from here. Now, I purposely didn't do it because apparently LinkedIn might uh punish it a bit if you automatically post on LinkedIn. So, I generally prefer to just copy and paste it. Uh but you can definitely set it up. So, this is just what I built very quickly. I definitely would add some things if I had more time, but uh yeah, I'll get into the building from scratch right now. So, at this part of the video, I've yet to actually build the entire system. I'm going to build it live from scratch so you get an idea of the thought process behind building a system like this. Uh I did plan it out a bit. So I just want to take you through my initial idea of uh the system. And planning is part of a process of building a productized AI system. I'm going to try to wing it uh do it all in all in one take. So we'll see how it goes. I'm sure I run into some errors. But it gives you a good idea, I think, of what it actually requires to build a system like this. Now before going over the planning uh what are the requirements for it to be a productized AI system? First of all it has to be a resellable AI system right so it has to be pre-built and can be used by multiple customers without any customization. That doesn't mean it's a one-sizefits-all. Uh every company will need uh their personalization and the system to be adapted to their specific use case, their specific business. In this case maybe tone of voice etc. Um, but the difference is this is going to be built into the system and done by the user which I'm going to show you in a second. Second, in an AI system, we want to automate at as much as possible of the end-to-end workflow. The reason is be the more we can automate an endto-end workflow, the the more value our AI system is going to have and the more we can sell it for. Right now, this is going to be an MVP as a disclaimer because of course I'm going to build this live from scratch. In reality, building a productized AI system that's really valuable will take you a little bit more time uh than I don't know how long this tutorial is going to be, but probably an hour or two. Uh it's going to take you longer. So, this is going to be an MVP, but it will give you good idea of the infrastructure we use to build systems like these. Uh and lastly, uh for productized AI system, we want to have a user interface uh uh for uh people to manage the workflow in an easy way, right? and a in a nice user interface uh for people who are non-technical to be able to manage this workflow. So here's my initial idea of the LinkedIn content system. So basically I uh think we have we'll have four uh different elements. The first one is the strategy uh posting strategy setup. And here we really want to bring in that personalization because of course every company will need uh their LinkedIn post to be adapted to their specific tone of voice to their specific business and to their specific ICP. So we want the system to generate this for each company so we can personalize that when we're actually writing uh the LinkedIn post. Then for the idea for the input uh in this case I'm going to stick to two which is this system can repurpose blog articles into LinkedIn posts and YouTube videos into LinkedIn posts. Now in reality when I would build out this entire system I'd probably add some more uh maybe podcast maybe just with a simple prompt. you could think of more input uh data we can we can take uh to to create LinkedIn post of course uh but again I don't want to make this an 8 hour tutorial so I'm going to get keep it uh straight to the point and I think again it will give you a good idea of building this initial infrastructure we use for productized AI systems and you can easily build on top of this again also the template will be available in my uh in my community if you're interested then uh the next part is going to be the post generation and the scheduling now in the post generation we want to be able uh want to uh the system to be able to do a few things. Of course, it has to be able to write the actual post. It has to be able to generate images. Uh it also should include the tone of voice uh of the company and probably the business context of the company so it adapts it to their specific tone of voice. And maybe we can also add in uh different posting frameworks. So for example, a story based post, uh an insight based post, uh you can have sort of these different writing frameworks for LinkedIn and maybe we can add that into the system. And then lastly, we have analytics. Ideally, we want the system to be able to track the performance of these posts. And this is what we try to do with these AI systems is to try to make them sort of self-improving systems. So the advantage is if we uh can add this analytics inside of the system then we can use these analytics in uh uh when we're generating new posts again and use the best post to uh generate new posts right as examples for new posts and that you can imagine can sort of create start creating that self-improving system right so we're going to try to build this into now the way we're going to build it which you've probably seen already now in the demo is we're going to use the air table uh as a database. We're going to set up the automations in NADN and then we're going to have uh the interfaces set up through air table interfaces and of course the human is still in charge of managing the workflow through the air table interface. Now this is usually the way I plan this out is quite simple. It's like what should the user experience or flow look like? What is a logical sort of sequence to manage this workflow? In this case I thought of this one. It might change when I'm actually building but this is my initial idea. So first you have a main dashboard overview where it's basically just the overview of the system and they can uh uh select where they want to go in in which step what they want to do right then we have the company setup or the campaign setup. This is a step we almost always use in these productized AI systems and this is basically where you can add new companies to the system and make that personalization right where the system can uh generate a personalization etc. Then we want to also scrape some reference posts. So we want to feed the system when we're generating new LinkedIn posts with some reference posts uh that the user can select to sort of mimic that tone of voice or style of writing when generating new ones. Right? So we're going to add this in two. Then we're going to have uh content the content generation request where they can uh request new content generations. And then we have the human review and the human in the loop of course. uh and where they can schedule and then ideally we built in a content calendar too. So this is just sort of the user flow inside of air table interfaces. Now what do we need here for the back end? Uh so here in this part in the company setup and we're sort of going to personalize it for the specific company. Uh we probably need one or two automations. The first one I'm thinking is to generate a business overview, right? And the ICP for the company, which we're then going to feed in again to this into the system when we're generating LinkedIn posts, right? So, this going to be the first automation. I'll just make it red so we know this is an automation. Uh, and also we want to scrape some reference posts, right? and their analytics to first of all have that analytics built in but also to use these reference posts when we're writing new ones to sort of mimic that tone of voice and style. So, uh generate or scrape LinkedIn post and this of course can come from their own business or can also come maybe from from other uh people on LinkedIn they they like the the style and tone of voice of. So, scrape LinkedIn post scrape reference LinkedIn posts. So once we have that, this would then only be an interface where they select the ones they want to use as a reference post. So we don't need an automation there. That will be done directly on air table. Then in the content generation for now we're going to use two, right? which is going to be repurposing uh YouTube URL to LinkedIn post and the second one the blog blog post blog URL. All right, so these will repeat the two two automations here and of course we're going to use this information when we're generating the new post. So it's personalized for each business. And the idea of this system is of course you can manage multiple businesses inside of the same system which I'll show you in a second. So these two will feed into this to make it personalized for each business. Then we have the human review which can be done directly on uh air table. Uh and the scheduling too. Maybe we can add uh one more here or actually in the last one where they can actually if they've scheduled it, it can also automatically post post on LinkedIn at the time they scheduled it for. So this is my initial idea. Again, this might change when I'm actually building, but this is the initial idea. So first, of course, we have to set up um the Air Table base. And if you don't have an Air Table account yet, you do need for building systems like this, you do need a pro account, I think, which is $20 a month, I do highly recommend uh to get that plan. Uh why do you need that plan, by the way? To do automations and I think to set up the the Air Table interfaces. I do really recommend to get that plan if you don't have it yet because if you learn how to build systems like this, it will it will uh pay you back multiple times. So, we just uh create one from scratch. We're going to call it uh a LinkedIn let's say we're going to call it LinkedIn agency in a box. This is how we call these systems because of course you can almost see it as a LinkedIn agency uh in a pre-built LinkedIn agency because we can manage multiple businesses inside of the same system, right? That's why also we call our SEO system an AI SEO agency in a box. So we can give it a name and now of course we first have to set up uh the first tables. Now the way I approach this is usually just to go step by step. Now for this main dashboard overview, we don't actually need a table. We can set this up directly inside of air table interfaces which I'll show you in a second. And then we have to create probably this one and maybe this one these two uh tables for now. So the way I do it and you don't have to do it like this is usually I use claude with uh the air table MCP to help me set up these fields a bit quicker. So, first we're going to delete the ones we already have. So, we probably don't need them. Uh, if you don't know how to connect air table with cloud through MCPS, I do have explain it the step by step uh in one of my previous videos which I'll make sure to link up here. Of course, you can just add them here to the fields, but I'll just show you how I usually approach it. So I just go to Claude and go, "Hey, please help me add fields to the LinkedIn agency in a box. Uh let's just give this initial table name." So we're going to call it company setup. Here we're going to manage the different companies. So in in the uh company setup table, I need the following fields. Now this is the part where we have to start thinking a bit on how the system looks and of course we can change this while we're building but the initial idea again is to generate sort of that business context a business overview uh the ICP of that business and maybe we can add in a value proposition so we can feed that into the system when generating a LinkedIn post um because of course we want those LinkedIn posts to be written from the right sort of business context and towards the right ICP. So in order to do that uh we probably have to scrape their website or maybe use perplexity to do some research on this company to generate those those uh three sort of data points. So what we can do is as input fields that's the way I think about it is of course we need the company name which is going to be a text field right then we're going to have maybe a company URL which we can then use of course to scrape or use perplexity on uh company URL which is going to be a URL then we have let's say maybe the company LinkedIn URL to get some more context uh that should probably be enough for those three data points And then of course also we want to generate some reference posts, right? So I can maybe go with the user LinkedIn URL. If I think about myself, I'd probably want to add some of my own LinkedIn posts there as reference post. And maybe we can add in some other people's LinkedIn of people we like the the style and tone of voice of. So let's say reference LinkedIn URL, right? Maybe can we can add a second one two and then what we need is of course a trigger to start the automation. So uh what we can do is what I usually do is just set up a checkbox and that could trigger the automation in NA then it's again I'll show you in a second. So, uh, generate information. And this is going to be a checkbox. I'm thinking I forget anything. That should be good for now. Let's just uh do it like this. I'll show you quickly how this works. And you'll see that it automatically starts adding these fields in the air table for us. So you can see it first lists the bases to find the right base. You found the company setup and you can see now it's start starting to create the fields here. Of course you can do this manually too, right? But it it helps me save sometimes and sometimes I ideulate a bit together with cloud what the what the the different fields should be, what the different columns should be for a system like this. So good. I think we got everything. So I think we're all good here. Uh now the name this one we can actually change the primary field. So air table we always need a primary field and we can go with company name right and then we can delete this one. So let me just put in uh a quick my information. So Benai. All right good. So we have some uh reference LinkedIn posts. Now you can also this is the nice thing with claude if you want to just populate the initial data right you can use cloud to make some dummy data right so we can say generate uh a record with some dummy data

**[205:01]** you can you'll see it'll start adding some dummy data then we can maybe right away add one more table so you can see here, right? We got some down here. We can delete these two. Then we can add in one more table where we probably want to put uh the reference post. So, we're going to scrape, of course, these these uh LinkedIn profiles to get the posts from. And then we want to have one more table where we can uh select the post we want to use inside of our system when we're generating new LinkedIn posts. And the reason also to do this in a separate table is because we don't want to have it really messy all inside of one. And second is al also for the air table interfaces which I'll show you in a second. So I'll set this one up just manually so you get an idea. So let's say select uh reference LinkedIn posts right and the information we're not I'm not completely sure what information we will get from the LinkedIn scraper yet but we can just put an initial ID and change it after. So probably we want the creator name or creator profile URL because we're going to use different LinkedIn URLs, right? Mine or Alex Arosi, etc. So we want to know whose it is. So we go create a profile URL. We probably want uh also the URL of the actual post URL. We probably want, of course, the actual post post content. Uh, we might want to have if they have it, I'm not sure yet, but the likes, right? Because this can really help us build that self-improving system. If we can track and see the best performing posts, we can always use those when generating new ones, and then it can become sort of this self-improving system. So, let's say like is probably a number. Let's see. I don't know how the scraper will work exactly. Um, and then we do maybe comments if they have it. The number of comments.

**[207:11]** Yeah, that's fine. Comments. Uh, let's see. Anything else we need? Of course. Then we can delete this one. And we'd also need to select the reference post because if we have many, we don't want to select everyone. We want to select the best performing ones or the ones we like the tone of voice most of. So, let's just go again with a checkbox. Select and there we go. Select the post. Maybe we can I'm thinking maybe add in one more because probably we can get some image URL too from the post image URL. So I'll show you how we're going to set up this automation in a second. But first I want to show you how to build this initial user interface here in air table for these two tables. So let's just put this one here. Good. So now we got the first two set up and from here we can also start the first automation. So let me first show you air table interfaces. So here at the top you see automations we're going to use to trigger automations in naden and interfaces we're going to use as the main interface. Right. So, as you can see here, it's quite an easy way in Air Table interfaces to build a nice sort of uh user experience uh without too much hassle. You can do it really quick, and it really does make it look a lot better, especially when you're trying to sell this to clients. It will be a lot easier for non-technical people to manage this workflow instead of going through these sort of tables here. We can just go here on in start building and then we can go uh build an interface. We can call this uh LinkedIn agency in a box. I can change the icon. And then you can see here you already get some layouts uh uh layout options here. As you can see, we got timeline, calendar, form, dashboard, overview, record review, and you can also build them from scratch. Now, I already like uh many of these layouts here, so I generally just use the layouts. Uh but you can also do it from scratch. But with the layouts, you can really do it really fast. Now, for the first one is that that's just going to be the overview, right? So, we don't have actually have it connected to the tables yet. This is just sort of the the the homepage of the main dashboard. So, we can just click here on finish. And you can see here we have the overview here. Again, we can call the LinkedIn agency in a box. And then here you can add all the pages, which we're going to do in a second. Then we're going to you can see here on the right side we can basically adjust things right. So in this case I don't need that sidebar and we can add a cover image too. All right now let me set up the first page. So you can just here go here on the plus and add a page. Now for the first one we want to have sort of that company setup right the the company personalization. Now the way I uh because almost all our AI systems have that screen that initial setup screen uh and the one I like to use for that one is the record uh the record review. All right. And you'll see how that looks in a second. So here we can just select the table. In this case we're going to select the company setup table. And if I click on next here we can already select what we want to show in this table. We want to show everything. So of course what I forgot in that system is the actual output when we generate this which we do want to put there. So we can set up a name here. Let's say campaign setup. And now you can see here we got the companies we can manage uh the LinkedIn for and here we have the input fields. All right. And if I just click here as you can see right now if I preview this it's not editable. Right. Of course, we want the user to be able to put in this information by themselves. So, we have to make that editable. It's really easy. We can just go here and click on editable. We want everything to be editable.

**[211:12]** All right? And the generate information is going to be the the action for the user, right? So, that one of course should be editable too. So, as soon as they put the check mark, the automation will be start running, which I'll show you in a second. Now what we miss here of course is the actual output information right which is going to be the business overview the ICP and maybe the value proposition. So that we still have to add in uh these fields here. So, we're going to business. Let's say that's going to be a long text. Business overview

**[211:48]** ICP and maybe the value proposition.

**[212:01]** So if we go back to our interfaces, we want to also show those three boxes because when the system generates those three things that's we want to have that human in the loop so the user can still adjust some things in that business overview in the value proposition, adjust some things, change some things um before actually uh generating the LinkedIn post, right? That human in loop in our experience is really important and that's the nice thing here in our table interfaces. We can build that in quite quite easily. So we can just click here on the plus icon and then we can generate the field or show the fields that we haven't showed yet which is the business overview. You can also do it here by the way. Business overview uh value position and ICP. And again these also have to be editable. You can see we'll be able to manage multiple businesses here. And of course the user also needs to be able to add new companies to the system. So the way we can do that is by adding in a button to basically create a new record in the air table in the back end, right? But we can do that through a form here which again the user experience is a bit better. So we can go here with add a button, right? And here we can define what the button does, right? Uh add no this is not it. Ah here we have to select add record to a form. Now we can delete this one. Remove and this will be the form. And if we click on that we can uh adjust the form here. So we can say add a new company or campaign and then here we can define what information we need. Now this is going to be only the input information. So company name, company URL. Maybe we can leave this. we can just do the company name and the rest they can fill out once the company's set up. So for now we can take all of this away and just ask for a company company name. So as soon as they fill this out I can show you an example. If I go preview here I select this and I want to add a new company I want to do LinkedIn post for. I can just create and you'll see it appears here. Then I can fill out the input information. Generate the information and the system will generate these three. Now before setting up the automation, let's set up one more page here which is selecting the reference post. Now that probably going to be a list because we're going to have lots of LinkedIn posts. Uh and we want the user to be able to select the ones that they want to use as reference post when generating new ones. So we can go here in list and then we select select LinkedIn reference post and of course we don't have any data here yet but we do want to show comments likes and selecting the post and it's going to be important here which I'll show you in a second that it's linked to the specific company. You can imagine if we have scraped let's say 30 LinkedIn posts from my for my company's campaign uh versus Hopspot. We do want to separate those in this this field, right? So, we're probably going to have to group it or actually we will have to uh link these two tables, right? So, we want to make sure that all the scrape LinkedIn posts are linked to the original company. And the way we can do that in air table and this is really important to understand when once you're building these productized AI systems is to go with link to another record right and there you can basically link it to another table. There you go allow linking to multiple records. We can skip this for now. And what you'll see now it's automatically added this here too. And now here we can decide we can select the the the company. All right. So this belongs to and you'll see now in the interfaces that we can also uh let's say group by and then we can group by that company. So you'll see it already grouped it by bi and there's one empty one and we can delete that one. Ah okay because this one's not linked yet. So for example, if I go this one, this one, then you'll see we get the LinkedIn post then in that uh for each specific company. Now I'll show you this one in a second when we set up the first automation. So the first automation the purpose is to generate this business overview value proposition and uh ICP and also to scrape uh some reference posts right that users will be able to select here. So how do we set this up? We go here to automations and we want to trigger this of course when that check mark is checked. Now how do we do this in air table? Pretty simple. We can go here to automations. We can click on add trigger and then when record matches condition. So in this case we select the table company setup and the condition of course is when generate information is checked right and when that happens we are going to run a script. Now, we use always the same script for these air table automations, which I'll make sure to uh here. Here we go. Air table. I'll make sure to add that together with the template. But basically, what this script does, it can trigger a web hook in NAN that can trigger our automation. Right? So, you can see we have three variables. This is a web hook, the record ID, and the action. So, we have to define those inputs of those three. Now in this case we don't really need an action. We can I'll use an action too. So uh let's say record ID record ID. And it's important here to match the exact parameter here. All right. Uh also with the caps and then we have to because this is where we're going to send over the the record ID number because that's going to be able allow us to get all the uh information from all the fields from that specific record. So we select air table record ID. We select the web hook, right, which we don't have generated yet in N, but we'll need to define that. And then we have also action. Now the action we can leave blank for now. Uh that I'll show you later why you would need an action. Uh so I think we're good for now. The next step is just going to be to set up a new N workflow. Right. So we start of course with a web hook to be able to trigger the automation. I'm going to use test web hook just as we're testing and all the way at the end I'll switch this to production URL and then I add this one in web hook and then I can uh test it out quickly. Test workflow right I go to air table and I click on test action.

**[219:14]** And now this should run. Yes. So now you can see the information we get here is the record ID and the record ID we can use to get all the information from all the fields from that specific record. So we can just use the air table node to get a record. Right? We're going to choose of course our base LinkedIn agency the box from list company setup right and then we pass in the record ID and you'll see now we get all the information from that specific field now the next step is really first to generate that business overview the ICP and the value proposition proposition right now I'm thinking there's really two ways to go about this we have the company URL and the company LinkedIn URL. So, we can either scrape the website and the company LinkedIn or we can use Perplexity to generate this for us. So, I'll do the quicker method for now, which is probably going to be uh to use perplexity. So, I use an AI agent that has Perplexity as a tool to generate these three uh things. So, let's go define below here. In general, I'll put I'll put in the the variables that the agent has access to. So in this case, of course, that's the company name. We drag that in the company URL.

**[221:00]** Add a company link and URL.

**[221:06]** Now to write these prompts a little quicker and by the way I'm going to put uh require specific output format uh which basically allows us to get multiple variables out of this one agent because of course you want to get three different data points which is the business overview the value proposition and the ICP. So I'll show you this in a second and then we're going to add uh in the prompt. Now for prompting a little bit quicker and faster. I usually use uh my uh prompting tool which I've set up in uh ChachiPT. So it just helps you basically uh write these prompts a bit more structured and use some more be best practices when writing these prompts. But it also helps me write them a lot faster. Right? So uh please help me uh write a prompt from scratch or actually yeah let's do that. And then I'll just come up with the prompt for the prompt right there quickly. So I've come up with a quick prompt here. Please help me generate a prompt for an agent. Here's the user prompt variables this agent has access to. This agent should always use the complexity tool to do research with the variables it has access to to generate a business overview that describes what this company does. A value proposition of the company and describe the ICP. Avoid marketing talk. Be factual. It's important because of course it doesn't serve us to have any uh high piece of text in there. Uh I always pass in these variables. So the prompt writer knows what variables it has access to and then the output format should be adjacent with the following keys according to the three output we need. Right? So I think maybe I have to be a bit more specific but let's see what it does. If you're interested in this prompt writer I also make sure to um link it together with the the template of this video. So your world-class research assistant with expert level uh skills in market intelligence objective generate a clear objective and concise business overview based on the company data. Think step by step.

**[222:58]** Now in general you do want to sort of look over these prompts quickly. All right. Is that Yeah, it looks but it looks good on initial note. I'll just test it out. If it goes wrong I I I'll change some things. uh make it into put it in put it in one copyable box.

**[223:22]** So good. I can just copy this, go back to NAN and add it in the system prompt. Now we don't necessarily need this here, but it's fine. Uh yeah, this should be good. Let's try it out. And of course, we have to still uh add a chat an L&M to this. I like to use the Google Gemini models. Let's go with 2.5 flash. Let's do that one. And then we have to uh we're going to add in that output parser, right? To get the three different um variables back, right? So simple way to do this you go here to define below as my agent or my prompt writer already has uh understanding on what we expect in terms of the keys we can just ask the prompt writer. So uh please generate a schema for a structured

**[224:27]** so please generate a schema for structured output par and then for this agent. So it already knows what I expect. So you see it already does it. So we can just copy this,

**[224:40]** paste it in and we should be good. Now we have to add in the perplexity tool. Now fortunately there's no native integration in an alien with perplexity. So we have to use an HTTP request uh to set up the perplexity. Um now I will I will set it up very quickly. I don't want to bore you too much uh with the setup and then I'll walk you through the setup. So, I've set up the perplexity tool. I gave it a quick description. It's always good to give your agent uh a description on what this tool does. All right. Again, you can read this all in more detail in your own time if you want uh to copy the template. Right. Then uh I use the the perplexity API, the chat completions. Uh now for I've set up the the authentication right which you need the perplexity API for. So if you don't know you can get your perplexity API key. You do need uh to upload some credits but if you go to your account you go to settings here in the API keys you'll find your API key uh which you'll need to to set up that connection. All right. So I've set up that here in the uh credential type. All right. And for the headers it's one header content type application JSON and we have uh a body which is uh a JSON in this case. So where we define the model so we have the sonar pro then the messages right and uh here we have the content and here basically we add in the query and in this case I use these curly brackets here with the query to be able uh for the agent to fill in uh this placeholder. Right? All right. So here we can define what the placeholder is query the query is used for the search etc. Right? And here we instruct right what what our perplexity uh tool should do or how the agent should use the perplexity tool. So let's test it out. Select connect this. Now this is probably going to be done with the dummy data. So this company probably doesn't exist.

**[226:51]** All right, good. We got it back. All right, so we got the three data points. You can see it's with the dummy data. So I can uh I can do it quickly with the other one with mine. So here we can define the record, right? Choose the record. Okay, now we we can turn this on, but we have to actually go back here, right? And select generate information, right? Then it will appear here as the choose record and then we can test test this one. We go here and test workflow test action. Can see now now it's doing it for my company.

**[227:41]** All right, got it back. Let's see. BI specializes in providing AI automation, implementation, consulting and education services to businesses. Uh they offer pre-built AI systems like SEO agency in a box. Custom AI solution development. So this is pretty good. Ben AI enables business particularly high growth companies to leverage AI for operational efficiency, cost reduction and accelerated growth. This is good. Ben AI targets high growth companies and businesses seeking to adopt AI for improving efficiency and driving growth. include organizations needing automations in such as sales, marketing, SEO, and generate operations. So, pretty good. Sure, we can improve it a bit, but uh good for now. Now, next step is to start scraping some reference posts. Right now, what I use for uh scraping is usually a relevance tool. Relevance AI has a built-in uh LinkedIn scraper. So, I usually I've set up a tool already. Uh here you can see L and then uh LinkedIn post scraper that I use for for automations too when I would need to scrape uh LinkedIn and basically this can take multiple LinkedIn URLs scrape them as you can see they have a built-in LinkedIn scraper. I'll make sure to also uh uh share this tool with you in in the template and we get the user post and we format the data a bit through JavaScript code. So the way we can set up this API is here to API. Here you get all the information. So let me set this one up quickly. Again, we need an HTTP request. So I've added the um the relevant AI tool. So here we have the URL, right? You can find out information how to set it up here in the API, right? We have the endpoint uh the sample curl. You can just copy that, right? The sample curl and always paste it in right here to set it up a little quick. Now there's one more thing. What you'll see is it actually expects an array, right? Because it can handle multiple LinkedIn URLs as you can see. So it can expect multiple, but we have to transform it into an array. So we have to add in one more step here, which is going to be a set fields where we're going to transform the three LinkedIn URLs that we want to scrape, right? The user LinkedIn URL, the reference LinkedIn URL, and the reference LinkedIn URL 2 into an array. So the way we do that is We select here array and then we add the three uh different links. Now what we're going to do is we're going to take away these curly brackets and separate them by by a comma. Right? Same here. We have a comma. I'm going to take away the curly brackets. And then we need to add in uh square bracket to create the array the end and the beginning. Now you can see we get an array. All right. So let's test this. Yes. Now we get an array with the three LinkedIn profiles. Um now one more thing here because we can't pass in an array directly. So uh the way we have to do this is make it into a string. All right. So we can do that through an expression. An expression you use a lot actually in in nan right is JSON dot stringify and then you put the the variable in bracket. All right now let's see this should work

**[231:19]** good. Now we got the LinkedIn posts and we got them all inside of one one JSON. So we do have to split this out. Why? Because in with Air Table, we're going to upload this to Air Table. Of course, it's a lot easier if we uh just use the create a record uh node instead of the batch update. That one's a bit more complicated. So, we just want to uh use the the create a new record node for all the different LinkedIn posts. So, we're going to split this out. We're going to use this one. And now you can see we got nine items. All right. So, now we're going to up update this data inside of the air table. All right. So, we can go air table create a record. So, first we're going to update these LinkedIn posts. So, we go to from list

**[232:25]** reference post.

**[232:31]** Select reference post. And then we're going to add now we're going to see if our initial ID of the columns make sense. So, we do actually have the likes. We do also actually have the comments URL is empty, but it does exist. uh creator LinkedIn post URL the post content and this one is going to be important right this company setup you remember this is the the the one that links it back to that original company to the table right so if we go here it's this one that links it to that specific company which is important now how do we link that is basically we can link that to the record ID of the company so I'm going to show you that so the way we can do that is to reference the original record ID from the company. So we can go to that first air table node, right? And we can just take uh the idea ID there and this field is always an array, right? Because you can add multiple. So we we have to put this again into the square brackets and then we should be good. All right. So, let's go back to our table. See if it worked. Yes. Now, we got the post. All right. We can delete these. You can see now it's automatically linked to my company. All right. And if we go to the interfaces now, you'll see that it added it to mine. See, now we have it grouped by by company. So lastly of course we have to update also the business overview the ICP and the value position. So in this case we can use update table record.

**[234:29]** Then we select the company setup. Now the columns to match on uh we can use the ID. So we go back to the original air table one. We select the idea ID. Now company name already had. So we can delete this one. If you delete them, it will basically keep it on default. Uh so these are all the input information. So we we don't need those. Also this not one not. So only the output information. is going to be the business overview which we get of course out of the agent business overview the value proposition ideal customer profile and here we also have to select the reference uh LinkedIn post which we don't have to because that's already set up in a step before so we can delete this one too the step and good should be updated now. So if we go into company setup, you can see it updated the business overview ICP and value position for Beni. So good. We got the first part of the autoation set up. If I go back to interfaces again, you'll see also in the campaign setup. Now you'll see that we get the business overview here and value position ICP. And this is where what the the company or the user can then still change and iterate on here to have that human in the loop. Of course, we're going to use this later when generating the new LinkedIn post. So the next step is to create the next step in the process which is going to be to request a new LinkedIn post, right? To actually generate it. So it's going to be requested. We have we have to have a way to request that post and to output it here into the interface. So we can probably do that inside of one. We'll need two tables. I'm sorry if this is not completely structured. It is because I'm doing it on the fly. Uh but we can go probably have two tables. So we have a request LinkedIn post table, right? And for this one, of course, we need to have a few fields. The first one is probably going to be the type of repurposing. So can we have the let's see single select? No. as the as the main field. We can't have that. So, let me just put it here. Edit field. Right. So, type of repurposing. We use a single select because we have two types, right? YouTube for now. If I build this out the system, I'd probably add some more options, but we'll keep it easy for now. YouTube and blog, right? Then we want um what else do we want? Of course, we need the repurposing link as an input field. So, it could be a URL. Um, then maybe we can let them give some custom instructions which we can feed in. So, if they want something specific to be generated in that LinkedIn post or specific, I don't know, call to action or instruction, we want the user to be able to do that. So we can go with custom uh instruction

**[237:47]** also. Maybe we can do the same for the image. So we can do custom instructions for for image.

**[238:04]** This one we can delete. Uh, so we have type of repurposing, repurposing link, custom instructions. Maybe we can let the user decide a CTA, a specific type of CTA. So let's say for example, visit, visit website, maybe a comment or uh what else? Follow for more follow. Uh so call to action anything else and then of course we have the output right and the output actually we're going to keep this table only for requesting right I'm going to show you why in a second so this one we can actually delete so we'll make change the primary field doesn't really matter to the repurposing link uh now we might add some things later but I think for now we're good one more thing we have to again link it to the original company. So we set that up here in the company setup. We link this to this request LinkedIn post. Create the fields. We can skip this. And now you'll see again, right, we have the company. So it links it to that specific company. All right. So I think we're good for now. Now, now for the output, we want to create a new table uh which this is where the the generated posts are going to be be generated, right? So we can go uh generated posts right in this case of course maybe we can have a post title just a a short description uh post title maybe we can have uh of course we have the post content

**[239:54]** we can have let's keep it simple the image URL that we're going generate with OpenAI. So, uh URL image URL maybe we can output the the the CTA too. Uh we already have that in this one. Not really necessary. Post title post content image URL. Keep it simple. Probably we keep it at this for now. Uh and we can always add later. And then we create a new interface. And I think what would be nice is to have a gallery where we can sort of show the generated LinkedIn post with the images right away. So we use a gallery and then we use the generated post. Now of course we don't have any yet but they'll basically be framed here. And then what we can do is we can request let users request a new post with a button at the top. Right? So again we can go add records to a form add post. And here you can see because now it's linked to the generated post table, not the request, the LinkedIn post. But what we can do is go here and we can go source for the form, right? We can change that to the request LinkedIn post. We can edit the form and then you'll see it ask for the input data for the from the uh table of request LinkedIn uh posts. So of course what we need this we don't need. So we need a repurposing link. We need the type of repurposing. We can also change this probably to a radio button. We have the user has to define the CTA

**[241:45]** custom instruction and for which company it is of course. All right. So they can select the company here and then request a new LinkedIn post. Right. And basically what we're going to do is this automation we're going to set up. As soon as a new record is created, the automation will be triggered. So I think we should be good here. So in this case, we go to automations and set up the next step. So we click here on uh creating a new automation, right? And in this case is we're going to not use the when record match conditions, but we're going to go when record is created, right? Then we select the request LinkedIn post and again we use that script from before again

**[242:33]** again we have to define the input variables. So um the web hook which we don't have yet the record ID which can we define right here and the action right now in this case we're going to use the action because there's basically two routes our automation should go right because we have YouTube repurposing and blog repurposing so with the action we can route them with a switch uh node to the different actions right which I'm going to show you in a second. So we have action and this can be the value of the type of repurposing. So it'll fill out that variable. So we should be good. Now of course we need a web hook. And now we can start. This is a nice thing of course with N8 is we can use multiple web hooks. We use the test one for now. All

**[243:34]** right, let's just test it again. We can test the action. But of course, there is no no uh I have not added any data yet. So, let me just add one right. We're going to do YouTube repurposing uh the CTA. We're going to do uh comment and no custom instructions. So, comment and create. Right now, you'll see in the back end here that it automatically created that post here. All right. By the way, this one we can delete. All right. No custom instructions. Now, let's see if the NAN Yes, it was triggered. All right. So, of course, again, we get the record details first. So, air table, same thing.

**[244:30]** We add the record id get the information and now we have to route it according to the type of uh repurposing we want to do right so we do that through a switch node and that's why we have that action defined you can see because that action we get as information in the web hook and then we can just route it based on the type of action right so we can go action is equal to YouTube right at routing or action is equal to blog. You can see in this case it was routed to the first one which is correct which YouTube right. So here we first of course have to set up a YouTube um transcriber. Right? Right. So, we have to get the transcription of the YouTube video to feed into the L&M when we're writing the LinkedIn post. So, the one I like to use is the one in Rapid API. If you don't know Rapid API, it's a marketplace of scrapers, very similar to Appify. Um, but usually I find that there are some cheaper ones here and sometimes more options. So, could be interesting to check it out. Uh, the one I like to use is this one. So, it's really easy to set up too, right? You can just uh copy this curl here. Go turn it in, set up an HTTP request, you can import the curl, you paste it in, right? And it's already set up for you. And as you can see here, we get the URL, which we're going to change to our variable. So, if we test this step, good, we get it back. Now the only issue with this scraper as you can see is we get every sentence separate in a separate chunk and we also get these timestamps which are really not not necessary for us. So, what we're going to do is just clean this up uh by putting in a split out. So, so first we're going to split out all the chunks. As you can see here, this array I'm going to test. Right now, you can see we get 932. So, now we get it all all separately. And basically, we want to take out only the text and put it together into one again. So we can use an aggregate node, right? And now we use only the text fields to aggregate, right? You can see now we only get the text back. Now this is still an array. So we want to turn this into a string. So we can use set fields because we want to turn this into a string to be able to pass it into an L&M, right? So we pass in the text, right? And we uh choose string here. And now we're getting into a string. So we're good. Now we have to set up the blog one. We're just for now going to set up a simple web scraper which is a right get HTTP get request. You can also use other types of scrapers right through to through through uh rapid API or amplify etc. But most pages you can actually scrape through a simple HTTP get request. So all you need to do is just we have to add in that repurposing link. Now of course this is a YouTube link. Uh but this would be the blog link and this would scrape it. So that's it. And then we can use probably clean it up a bit. This is usually what I do after the get request. And we have to execute this previous nodes. We can't test it right now. Let's just finish it up with the YouTube one and then we'll do the blog one later. But we should be good with this. Maybe we can define the same destination key. So here we save it as text and here we save it as data. So we can change this here too. And then basically we can reference the same variable at the end. So what what we do here to make put them together again is no operations. So this node basically we can put the two two workflows together again. And now of course we need to start generating the LinkedIn post and the image right but before doing that we do need the data the the company data right the business overview the ICP and developer position and also the reference post that the user selected right so we're going to first use the air table node again to get a record get the information from the initial base right So

**[249:28]** and then we need the information from the company setup right the business overview the value proposition and the ICP. Now the record ID we can find now in this as you remember this is the request uh LinkedIn table right but of course now we can get the information from that first table still by referencing that company setup because this value is basically the record ID of that original company. So this one makes allows us to get the specific information from that record in the company setup. So we can just put this one here and remember we always do have to put in those square brackets for that specific field right because it's an array. Now you can see we get the specific record ID and there of course we can get that information from the business overview right the ICP and the value position and all of this we want to pass into that AI step and of course we also have to do the same for the reference post. So we have to find the specific reference post that the user selected. So if I go in this case we probably go with search records because we need multiple to retrieve multiple. So air table search records.

**[250:55]** So we go with this one. Now you can do this through a filter too because of course we have to filter it by the company the specific company and also by the post that were selected. Now we haven't actually done that. So we're going to just set that up quickly. So basically we can just say okay let me select these three as reference post right in the interface. We can also set have that right. Uh at the moment we don't show that field. Yes we do. All right. So the user can basically select no, we have to add that as an option. So we have to be able to edit this column inline. Okay, we have to change that here. So edit records inline that basically allows the user to edit this. Now these we don't necessarily want them to edit. So you can go on each one separately and disallow it. But this one, of course, we do. So, you have to play around a bit with air table interfaces, but it's it's quite straightforward. So, these ones we're going to deactivate. And now we should be able to yes, select them here. So, here the user now can select which ones to use. We can show this a bit better. The interface giving it a bit more space here. For example, we can go with the row height. And we can change this And then I can open it to to uh see the whole post. And maybe we can sort it based on likes. So it becomes easy for the user to select the best performing ones. So let's do sort by likes.

**[252:45]** All right. So let's just select four for now. Good. So these we want to retrieve two in the automations of course. So we can do this by formula but I don't want to confuse you too much for now. You can use a air table formula but we're just going to retrieve them all and then uh we're going to use a filter after. So retrieve all the LinkedIn posts and we can just use a filter right and we can go first of all of course the post has to be selected right so we can do select the post is equal to true now you'll see this is actually a boolean right so we'll also again have to stringify this right the expression to make this into string, not a boolean in the brackets. What did I do wrong? Jason string if I

**[253:52]** Yeah. So, this is I don't know why this is red because it does work. Uh but then we have uh the second condition of course is that it's from this specific company. So, we can go and basically match this, right? the company setup to the original company. It's just the note we used here. So this ID should basically match this ID. I hope that makes sense. Is equal to this ID.

**[254:29]** Good. So we got four four items. That's good. And also these are four items. So we need to aggregate them into one. So we can go all item uh data into a single list and maybe we can do only all specified fields. So only we need post content. We only really need that, right? That's all we need. So now we get it into one. Now, this of course is an array. So, again, we have to use the set fields to turn it into a string to be able to pass it into uh the L&M, right? So, we make it into a string and good. Now, let's connect this one too. So, we have to add in a quick example just to make sure this one works. And then, we're going to use the mo we're going to add the most important part of the system, which is the prompt for actually generating uh the LinkedIn post, right? So let me just add in a quick example so we can test this one. So I've added in a quick example again. I'm going to just run the automation as a test. So if I go here test workflow. Now I'm going to select second one which is a blog post. All right. And now we have to test this one. Good. Should work. Yes. So, good. This one's connected, too. Now, we can uh generate the actual prompt. So, in this case, we're probably just going to use a basic NM chain. Now, the important thing here is to give it lots of variables and context, right, when writing this LinkedIn post. And this is probably where I'd put the most time when actually building this system is to make this prompt as good as possible. Uh so of course we want to pass in the information from the business. So business overview, the ICP and the value proposition of the business. We want to pass in the reference post and make sure that he uses that sort of tone of voice and style as much as possible. And lastly, of course uh the actual scrape blog post or or YouTube video. Uh so first I'd start with uh the variables of course uh we need of course the content which is like the YouTube transcription or the blog create blog post. Maybe we can call the content base which is going to be this. Right? This is why there's no operation to nothing. They're both combined into one data. So whether it's blog blog post or YouTube be saved in this variable. Um then we have the of course company information. So company name we can get this all from the from the first table right. That's a company name. We have the business overview.

**[257:30]** ICP

**[257:37]** value proposition. And lastly, of course, the reference posts,

**[257:54]** which I'll find here in this last one. All right, here we have the reference post. And now we're going to have to we're going to use the specific output format and add the prompt. So, I'll just come up with the prompt here. It's going to take me a little bit, but I I'll show you when I have the the end result. So, I've come up with the following prompt through the prompt writer. Uh, probably far from perfect. I would take a lot more time when I'm actually doing this, but this is the initial one. Again, you can read it all in detail in a second, but your highly skilled LinkedIn content strategist uh, etc. The objective is to repurpose the content base, right? I give it some context into three distinct styles of LinkedIn post because what I noticed is I actually forgot to add in the the the posting framework or the writing framework. So I just just decided to let the system generate three variations with three different writing frameworks. I have to if I would rebuild this, I'd probably add in an option for the user to choose choose a type of writing, right? But for now, just to not make this go on endlessly, I'll uh just let it generate three different types of of frameworks. Uh so each uh designed to resonate with the company's target audience and driver uh drive engagement. Think step by step the following process. Extract a core insight topic or take away from the content base. Right. Align each post with the company business overview. Ideal customer pro profile and value prop position. Closely analyze the reference post to mimic their successful hook structure, tone of voice, post formatting and stylistic flow. This, in my experience, works really well if you use this mimic almost mimic uh the style or tone of voice of the example post. That's sort of the best way in my experience of prompting it to sort of get that tone of voice because it can be quite hard, right? To to let an L&M really get that that style of tone of voice uh the same as the examples. Then integrate the CTA. By the way, I forgot that one. I'm going to add that as a natural closing thought. Uh right, because I still have to add that in the variables. Write three clear distinct post using the following strategies. Story based, insight focused and engagement focused. Right? So these are the three different types of of frameworks. Stay tightly aligned to the content base etc etc. Right? Uh so this is it for now. I still have to add in the CTA here which we forgot.

**[260:21]** And we have to add a Apple parser of course because we're gonna and we're actually going to generate three different uh posts. So let chat GPT generate this. This is going to be an array because it's going to be three different posts right with the different frameworks. And each of the posts will have a job uh title a post title. uh the post content of course the type of content is it a story based insight focused or engagement post and suggested hashtags I I don't think this actually still works but uh yeah we'll just add it for now and then we're probably for writing I prefer to use the openi uh uh models or or cloud but we'll just use uh the 4.1 for now 4.1 Good. Uh, now we should be good here. Let's test it out. There's an error. I think I made a mistake here. Yes. So, this should be defined below. Not generate from JSON example. So, to change this now, we should be good. Yes, now we got it. Good. the AI agent reality check story. So this is just a blog post I added right about AI agent versus reality this one right we'll look at this one these ones in detail uh in the air table but first let's generate also um the images all right so first as we have three different posts that we have generated we have to split them out and generate an image for each one of the posts right uh so we're going to just split out the outputs

**[262:20]** All right. Now we got three items and then probably we first want to generate use an N&M to generate a prompt for the image model, right? And we're going to use the OpenAI image mo uh model because it's really good at the moment. You've probably already seen it, but if not, it's really uh it's really high quality. So I'll just set this prompt up that's going to generate a prompt for the image generator. So I've set up a simple prompt. Uh I passed in the variables the post title and the LinkedIn post. And here so I also added in the additional important comments for image generation which is the custom prompt which we actually didn't put in. But of course we do want to add it here if we have it. Now I can't actually see the custom prompt because we didn't fill it out. But you have to test it once and add a variable here too. Um, and then I put in a simple system prompt, right? Use the data on the user message to create a prompt for an image generation model uh that will post it with this LinkedIn post. Make sure it adds value and it's clean. Only output the prompt. And then two example prompts. So just very quick, let's test it out. Ah, no, no, no models connected. So let's just connect it to the same one.

**[263:40]** Good. So, we got three prompts. So, then we're going to use the OpenAI uh new image generator model, which is really good, right? So, if you don't know how to set it up, um you first have to go to your platform.opai.com account, and you have to verify your organization. I have it set up in another account, but you basically have to go here to the settings and then general and then here verify your organization. All right. So, you have to do an ID check uh before you can do this. And then you can find the information on how to set up the API here um in the image generator images and vision. Here you'll find the information on how to set up uh the HTTP. But again, I'll I'll set it up for you right now. And then again, you can copy and paste it if you want to. So I've set up the the image generator model. So we use the images/g generation URL. Uh for the authentication you can just add in uh here in the parameters right authorization bearer and then you add your API key right for the JSON uh you use GPT image one right and then the prompt uh you can add in the the variable from that previous step right for the prompt and this should be enough right all right but again you can only get that API key for the image model if you're you're uh verified right so we can test it's going to take a little bit because generating images probably takes 20 or 30 seconds per image. So, it was generated. Now, you can see it's 6.2 MBs. So, it takes a bit to load, but you can see we get a B64 JSON, which is actually a file we can't do a lot with yet. So, we need to add in one more node here, which is going to be convert to file, right? And then we use move B 64 string to file. Going to show this. And then we're going to add in this B 64 and then we get the the data back here, right? You can see we got actually get a file here. Now, this is still a binary file as you can see. So, we actually need to host the image somewhere. Now, what I usually use to host these uh these images is imagekit.io, right? You can make a free account and as you can see, they have an image API and we can host these images there. So to to add it to air table and to show it in air tableable uh you can use this you can make a free account uh you can have 25 gigs of storage. So you can basically use it for free um but uh and you can find the API key uh once you sign up too. So I'll set this one up quickly. So I've set up the the API call to host these images and basically turn them into a URL. Right. So you can see we uh you need your API key which you can get from your settings inside of image kit. And then this you can leave the same if you're going to copy the template, right? So form data, file name, etc. Uh and here as long as you've uh your your files also called data, uh you should be good with these settings here. All right. So now we test the step here. It's going to take a little bit too.

**[266:51]** And now you can see we get a URL here with the image. So if I take this URL now, you'll see that we get the image in agent reality. All right now, in practice, you probably want to generate a few images. I would design this a bit different. If I had more time, I'd make it more modular, but I'll show you in a second what I would do to improve this system. But let's finish it up. Now we have all the information, and now, of course, we want to update our air table, right? And we want to create a new record in that last table with all the information we've generated. Right? So we go LinkedIn agency. Yeah. Box generated posts and then of course we have to add in all the fields. So we go to the split out node for the information. The post title, we have the post content. Um, post content. The image URL image URL. Where are we? Here. Here we go. Now, we only had three ones defined. Are there any other things? The suggested hashtags we probably want to add to the table, which although hashtags, nobody uses hashtags. Let's let's keep that out for now. Then uh what else can we add here maybe the content type let's add that. So if it's story based or not. So let's add that to the table here. So in the generated post you can go.

**[268:46]** I have to refresh this one quickly. Right now we have the content type there too. So we go to the split out and we add the content type. So let's test this out.

**[269:08]** Now there's one more important thing that I'm running it this that I'm forgetting which is again we have to link this to the original company. So again we have to add in that reference field of course in this content right. So we go to the company setup we add another one and we link it to the generated post. We create the field. Now in the generate the post again we can link it.

**[269:36]** So if we refresh this now we can link it to the original company. So we used that company setup one here or we can also just go through the original one and use that one. Again we have to use the array square brackets. All right, we test it again

**[270:08]** and good. Now we should be good. So we can delete the original ones.

**[270:21]** And now we can go to interfaces and make this look nice. So here in the generated post we can now want to also show the actual images. So you have here an option which is image field. Then we can define the image URL. So we get it right away here. And we can make it a bit bigger. So we can do two aspect ratio. Let's do square. This looks pretty good. And of course, we also want the user to be able to adapt this pose, right? So, we're going to use editable. This image URL we can put at the top. And again, we can show this display image. You can play around with this, right? You can also hide the label for example. Yes. So, and then content type and the company is yeah, this we probably want to add in too so it's clear for which company each post is. So, we can add that in here too. company setup, maybe the content type,

**[271:41]** and then we can make the post title. Yeah, that is the title. Okay, so that's all good. So, we don't have to show it here. Uh, and then we have the human in the loop to change things. Now, if I would rebuild this, I'd probably make it a bit more modular. So, first generate the LinkedIn post. Um, I' I'd probably only have it up until here. Then, uh, let the user generate multiple images uh, right in a separate workflow when he triggers it himself with an automation. Then probably want a review step. So, I'd probably add in a step here where a user can put in a prompt to what he specifically wants to change and then we can pass in the original post with the adjustment for the system to regenerate it. So I'd make it a bit more modular. And then of course you could also add in that automatic scheduling. Now maybe we can add the last part just uh so we have a content calendar. So we can go probably we can do that pretty simply. We can just go here with a checkbox, right? And we can go uh schedule post and one more date field with the date uh scheduled for right and then we can go let's say we schedule this one for tomorrow. Then we can just add one more page here and we can use the calendar view. And then we select the last table. can leave this as it is. You'll see now uh we get it here. And now we can also decide to let users still adapt it here. Right? Of course, you could also set up an automation that looks at those dates and schedules it on on LinkedIn, right? But uh it's been a quite a long one already, so I'll keep it uh at this for now. Uh in reality, of course, I'd spend a lot more time in actually making these LinkedIn posts a lot better. And we can look at it right now. It's not perfect yet. So you can see this the text is a bit too long. You can see this one. It did do some LinkedIn formatting, but this can definitely be improved a lot by by the prompt. Probably the reference posts. This one's a bit better. You can see this uses a bit more of that LinkedIn tone of voice. Everyone's calling 2025 the year of AI agent. But here's the real question for SMBs and innovators. Will AI agents actually revolutionize how growth companies operate this year? So you can see it targets my ICP and it really talks to business owners because it takes that ICP into account. Or are we seeing the next tech hype cycle useful for some processes but nowhere near full autonomy. From what we're seeing on the ground, agents can automate recurring workflows, boost efficiency for busy sales and marketing teams, service powerful assistance, but seamless one-click automation of complex tasks. Still a work in progress for most organizations, right? And you can see it at that as that call to action for this one which is you know comment. This is a story based right hype moves fast in tech. Recently I spoke with a founder at growth stage agency who jumped into the AI agent bandwagon expecting an overnight revolution. They imagined fully autonomous AI agents scoping out projects handling sales outreach even orchestrating whole marketing campaigns but reality set in. Not bad. Not bad, but I the formatting could definitely be improved. I could probably add in some more reference post. It would probably do a better job. Anyway, uh we can now set up and finish maybe this last part, which is the overview. So, all we can do here is basically set up all the different steps in this process. So, we can just add them here. And this then sort of becomes our main dashboard. Uh this we can rename to content calendar

**[275:43]** where we can change the appearance make it black and then we can add a cover image. I don't know. I just use all my websites. Images won't fit probably. Well, yeah, you get the idea. And then uh we're good. This uh of course you can spend a lot more time. You can make the system a lot better. But I just wanted to give you an initial idea on how to sort of build this infrastructure for AI systems. I hope you can see how powerful it can be. But of course, this takes a lot more time and iteration and building on top of this initial system to actually make it really valuable and and and and good and actually to to sell it to clients, right? But I hope this gave you a good idea uh uh just to finish it off here. You can click publish, right? And then you can also share this and then you can copy the link here. You can open it in a new one and then the user will only interact with the system here, right? So it doesn't have to go into uh into the Air Table base or or things like that. You can manage the entire system. Now, if you're still watching, first of all, congratulations. You're now probably ahead of 99.9% of the world in terms of AI and automation skills. Of course, this all requires a bit of practice, and it takes a little bit of time, but just knowing the infrastructure of these systems, understanding the tools, and knowing NAN will really allow you to start building your own AI products. So the question then is how do you come up with AI product ideas? Now in the last section of this video, I'll go over an easy method for finding AI product ideas and give you some specific examples on big opportunities in AI that I think you have today and how to go to market to find your first customers. Now if you don't have an idea for an AI product or an AI SAS yet, I want to give you this quick framework that helped me a lot when I first saw it and that is the following. Most people approach finding product ideas from the solution problem market framework which is generally a a flawed approach right so I see this happening a lot too in AI for example people learning NAN uh they can now build an AI agent or an AI chatbot so that's the solution they know they can build then they think is there some problem I can solve with this solution yeah sure I mean let's say old uh traditional website chat bots are are pretty limited maybe I can uh build a better one uh and then they think which market might need that. Maybe I can help e-commerce businesses with this solution. Now, generally, this is a flawed approach because you're forcing your preferred solution onto problems that might not even exist or are not painful enough for the specific market to actually pay for. And second, because you're thinking solution first, what you'll generally see is that there are lots of other players that already exist or hundreds of others doing the same. So, generally a far better way to find product ideas is to go to problem market solution framework. And this is the blueprint many of the successful businesses in the world have followed. They were born out of problems. So you can think of your personal life what ideally your professional life and what are some big some of the biggest problems you are facing on a day-to-day in your professional life. Right? Then you think uh let's say for example I work at a marketing agency and I uh do Facebook ads and I noticed that creating uh ad creatives and ad copy is actually a really painful and long process and really impacts the performance uh of our ad campaigns. Right? So that that might be a big problem you've identified. Then you think is there actually a market are there other people that really struggle with this? And you go like yes most marketing agencies have this pain point. Uh and then you build a solution around this. Now, let's say you don't have a big pain point in your day-to-day or they're unsolvable. It's hard to build a solution around them. Then there's a third approach which is definitely a good approach too, which is go market problem solution. And in this case, you can think of a market, a specific market first. Ideally, one you have experience in. So maybe you've worked in or you know something about uh but even if you don't have the experience, you can still follow this meth method. So you choose a market. So let's say I know e-commerce very well. Then you identify the biggest problems. Let's say I've worked in an e-commerce uh that my business had in that time. You think list out all the problems. What are the biggest problems? And from there, is there something I can build a solution around? Right? But even if you don't have that professional background or experience, you can still pick a market, learn inside of communities, talk to people about what their biggest problems are, and from there come to a solution. And that's why I think if you don't have that much professional expertise or you don't know an industry very well, the AI automation agency is actually a very good way to potentially find product ideas because as an AI automation agency, you're really starting to understand different markets, their biggest problems, and you're already being paid to build solutions. So that's the point I make in my last video too about how to scale an AI business. Uh so if you want to learn more about that approach, then check out my last video. And now that we have AI and new layers added to this framework which makes it far more powerful and gives us almost infinite new opportunities because every time we have a new technological revolution like the internet, the phone and now with AI we have a big update or something new almost every month with image generation APIs, video generation, N&M's becoming powerful more powerful by the day, MCP. Every time you have a new technology like this, it allows us instantly to build thousands, if not millions of new uh solutions that were previously not possible to build. Second, it will also allow us to solve far bigger problems. It will allow us to solve new problems that were previously impossible to solve and it will also create new problems that didn't exist before. And thirdly, because there's a new technology, there's instant market demand. The market knows they need to adopt this new technology. Think when the when the phone came out or the internet came out, every company now needed to be online, needed to be on an app, needed to have an app, needed to have a website. So there's instant market demand. So with a new revolution like AI, we have thousands, if not 10 thousands of markets. We have hundreds if not thousands of problems. So we literally have millions of new opportunities for solutions we can build. If you still don't know where to start, a big opportunity again that I see is going after the servers industry, right? especially the tech service industry, meaning marketing agencies, lead genen agencies, because they focus on revenue generating systems, right? Because this is really most one of the most expensive problems uh companies have that they're already paying for and can bring them high ROI and to not compete with the big players in the market. And I think there's a huge opportunity of focusing on niches, right? really small niches, building these systems for small niches, I think you have a very interesting value proposition because if you focus on these small niches, you'll not necessarily compete with the big players like uh uh 11x etc. Right? If you f if you build a great email outreach system for one specific industry like uh dentist or e-commerce, you uh can definitely provide more value than some of these bigger players and especially than than chatt. So, think email outreach systems for e-commerce, LinkedIn content systems for business coaches, ad generation systems for dentists, SEO systems for local businesses. Just a few examples, but uh I think you get the idea. How do you build a good product? Now, I just heard Mark Zuckerberg explain it very well. The faster you can get the user feedback to product iteration loop, the faster you can get to building a valuable product. And this, when you're starting out, really requires a marketing first or an audience first approach. It's very cliche uh but true. The recipe for failure is to build out a perfect product for six months just based on your idea and then go to market because user feedback actually builds good products. And this marketing first approach has three big advantages. First, you validate demand before overengineering your product. Second, you build what people actually want instead of what you think people want. And three, you're building distribution or marketing skills from day one, which is going to be the key to making an AI product actually work. And of course now the the product building and product iteration stage is really revolutionized right now with these coding agents and no code tools because we can speed up this loop uh by 10x or if not more uh through these tools and we can also build prototypes much faster. So that brings up the question should you build a product before going out to the market. Now my recommendation is if you already identified a specific problem uh of your target audience right then you can build a very quick one or two feature MVP right minimum viable product or a very quick prototype right if you don't know a problem yet but you've chosen let's say a specific industry you know something about then I would take the approach of trying to sell AI automation services and let the market come to you and tell you their biggest problems which can eventually lead into you finding product ideas then the next step is to really go out to the market Right? And your goal here is to find audience message fit. Right? And you want to keep this as simple and as lean as as easy for you to do as possible. But you want to validate the traction for your potential solution and learn from users on what to actually build. So the easiest way you can do this is by just setting up a very quick landing page. And what you want to do is you want to call out first of all your target audience, right? Your market. Make clear make sure that you're calling them out as specific as possible. If you already identify a problem and you have an MVP or a prototype, you want to add the problem and the solution also in your messaging because the better you can identify that problem and the solution you offer, the more traction you're going to see. And now the huge advantage we have with AI is if we mention AI, it will automatically almost create uh generate more interest, right? So even if you don't have a specific problem and a solution yet, you haven't built this prototype, this is the amazing opportunity we have in AI right now is even if you're just saying I do AI automations for e-commerce businesses, you can already sort of see traction which was traditionally if there's not a new technology is very hard to do because generally you have to really call out their pain points or their problems and the solutions you offer. So you want to set up a very quick landing page. I recommend framer, web flow I personally use. You can also use tools like lovable to spin up a landing page very quickly. And then you want to go out to the market and validate that that demand, right? And learn from your users. So you can use cold called cold email, you can use paid ads, uh you can use your network, you can use content on social media, but really want to go out there and validate your audience message feed, right? So you can call out multiple problems too if you're not completely sure to test out which gets the most traction, etc. But you really want to keep this simple, iterate, find the right message, send them to a landing page where you either have a weight list where they can just leave their email or a Calendarly link so you can actually talk to them. You can what a good strategy is in general is to ask for feedback. So you can give the tool for free for example in return for feedback. So you can learn how to build on top and make your solution or product better in the initial phases. And once you have a a better product or a better idea on what to build, you can eventually of course start charging. Now that's it for this video. Thank you so much for watching if you're still watching and thank you for hearing me ramble on for hours. But also congratulations because you probably got ahead of 99% of the world actually watching this video. Now, of course, to truly master this skill, you do need some actual building experience, but honestly, most of that you can also do while working with clients. So, you can really go out to the market and pitch AI automation services or even try to build out your own AI product. Now, now, if you want a bit more help on starting or growing an AI business, you can also uh check out my community where we help people just like you, hundreds of people uh to start and grow their AI business. We have unlimited one-on-one tech support, multiple templates, of course, get two Q&As's, me, me and my team, and we really try to help you with everything you need to get your business off the grind. So, again, thank you so much for watching. If you got any value out of it, I highly appreciate a like and a subscribe. If you want to see me build another AI product we built for a client, then uh check out this video
